[
  [
    {
      "timestamp": "2025-12-14 17:50:25"
    },
    {
      "user_input": "What is the fundamental difference between a Standard RAG pipeline and an Agentic RAG?",
      "response": "The fundamental difference between a Standard RAG pipeline and an Agentic RAG lies in their approach to information retrieval and processing.\n\n1. **Standard RAG Pipeline**:\n   - **Passive Retrieval**: It retrieves relevant information from external sources (like web pages or documents) based on keyword matches or semantic searches.\n   - **Augmentation**: The retrieved data is added to the LLM's prompt to enhance its responses, making them more contextually grounded and accurate.\n   - **Limitations**: It may struggle with contradictory or fragmented information and lacks the ability to validate or synthesize data effectively.\n\n2. **Agentic RAG**:\n   - **Active Reasoning**: Incorporates an intelligent agent that actively evaluates, validates, and synthesizes retrieved information to ensure accuracy and reliability.\n   - **Enhanced Capabilities**: The agent performs tasks such as source validation, conflict resolution, multi-step reasoning, and external tool integration to provide deeper insights and more accurate answers.\n   - **Complexity and Cost**: More complex, requiring additional engineering effort, computational resources, and potential latency due to the active decision-making process.\n\nIn summary, while Standard RAG retrieves and augments information passively, Agentic RAG adds an active reasoning layer that enhances the depth, accuracy, and reliability of responses.",
      "retrieved_contexts": [
        "207\nVisual Summary (Fig. 14.3)\n Key Takeaways\n\u2022 Knowledge Retrieval (RAG) enhances LLMs by allowing them to access \nexternal, up-to-date, and specific information.\n\u2022 The process involves Retrieval (searching a knowledge base for relevant \nsnippets) and Augmentation (adding these snippets to the LLM\u2019s prompt).\n\u2022 RAG helps LLMs overcome limitations like outdated training data, reduces \n\u201challucinations,\u201d and enables domain-specific knowledge integration.\n\u2022 RAG allows for attributable answers, as the LLM\u2019s response is grounded in \nretrieved sources.\n\u2022 GraphRAG leverages a knowledge graph to understand the relationships \nbetween different pieces of information, allowing it to answer complex \nquestions that require synthesizing data from multiple sources.\n\u2022 Agentic RAG moves beyond simple information retrieval by using an intel-\nligent agent to actively reason about, validate, and refine external knowl -\nedge, ensuring a more accurate and reliable answer.\n\u2022 Practical applications span enterprise search, customer support, legal \nresearch, and personalized recommendations.\nFig. 14.3 Knowledge Retrieval pattern: an AI agent to find and synthesize informa -\ntion from the public internet in response to user queries\n14 Knowledge Retrieval (RAG)",
        "199\nFig. 14.2 Agentic RAG introduces a reasoning agent that actively evaluates, recon -\nciles, and refines retrieved information to ensure a more accurate and trustworthy \nfinal response\nan \u201cagent\u201d\u2014a specialized AI component\u2014acts as a critical gatekeeper and \nrefiner of knowledge. Rather than passively accepting the initially retrieved \ndata, this agent actively interrogates its quality, relevance, and completeness, \nas illustrated by the following scenarios.\nFirst, an agent excels at reflection and source validation. If a user asks, \n\u201cWhat is our company\u2019s policy on remote work?\u201d a standard RAG might pull \nup a 2020 blog post alongside the official 2025 policy document. The agent, \nhowever, would analyze the documents\u2019 metadata, recognize the 2025 policy \nas the most current and authoritative source, and discard the outdated blog \npost before sending the correct context to the LLM for a precise answer.\nSecond, an agent is adept at reconciling knowledge conflicts. Imagine a \nfinancial analyst asks, \u201cWhat was Project Alpha\u2019s Q1 budget?\u201d The system \nretrieves two documents: an initial proposal stating a \u20ac50,000 budget and a \nfinalized financial report listing it as \u20ac65,000. An Agentic RAG would iden -\ntify this contradiction, prioritize the financial report as the more reliable \nsource, and provide the LLM with the verified figure, ensuring the final \nanswer is based on the most accurate data.\n14 Knowledge Retrieval (RAG)",
        "208\n Conclusion\nIn conclusion, Retrieval-Augmented Generation (RAG) addresses the core \nlimitation of a Large Language Model\u2019s static knowledge by connecting it to \nexternal, up-to-date data sources. The process works by first retrieving rele -\nvant information snippets and then augmenting the user\u2019s prompt, enabling \nthe LLM to generate more accurate and contextually aware responses. This is \nmade possible by foundational technologies like embeddings, semantic search, \nand vector databases, which find information based on meaning rather than \njust keywords. By grounding outputs in verifiable data, RAG significantly \nreduces factual errors and allows for the use of proprietary information, \nenhancing trust through citations.\nAn advanced evolution, Agentic RAG, introduces a reasoning layer that \nactively validates, reconciles, and synthesizes retrieved knowledge for even \ngreater reliability. Similarly, specialized approaches like GraphRAG leverage \nknowledge graphs to navigate explicit data relationships, allowing the system \nto synthesize answers to highly complex, interconnected queries. This agent \ncan resolve conflicting information, perform multi-step queries, and use exter-\nnal tools to find missing data. While these advanced methods add complexity \nand latency, they drastically improve the depth and trustworthiness of the \nfinal response. Practical applications for these patterns are already transform-\ning industries, from enterprise search and customer support to personalized \ncontent delivery. Despite the challenges, RAG is a crucial pattern for making \nAI more knowledgeable, reliable, and useful. Ultimately, it transforms LLMs \nfrom closed-book conversationalists into powerful, open-book reasoning tools.\nBibliography\nGoogle AI for Developers Documentation.",
        "200\nThird, an agent can perform multi-step reasoning to synthesize complex \nanswers. If a user asks, \u201cHow do our product\u2019s features and pricing compare \nto Competitor X\u2019s?\u201d the agent would decompose this into separate sub-  \nqueries. It would initiate distinct searches for its own product\u2019s features, its \npricing, Competitor X\u2019s features, and Competitor X\u2019s pricing. After gathering \nthese individual pieces of information, the agent would synthesize them into \na structured, comparative context before feeding it to the LLM, enabling a \ncomprehensive response that a simple retrieval could not have produced.\nFourth, an agent can identify knowledge gaps and use external tools. \nSuppose a user asks, \u201cWhat was the market\u2019s immediate reaction to our new \nproduct launched yesterday?\u201d The agent searches the internal knowledge base, \nwhich is updated weekly, and finds no relevant information. Recognizing this \ngap, it can then activate a tool\u2014such as a live web-search API\u2014to find recent \nnews articles and social media sentiment. The agent then uses this freshly \ngathered external information to provide an up-to-the-minute answer, over -\ncoming the limitations of its static internal database.\n Challenges of\u00a0Agentic RAG\nWhile powerful, the agentic layer introduces its own set of challenges. The \nprimary drawback is a significant increase in complexity and cost. Designing, \nimplementing, and maintaining the agent\u2019s decision-making logic and tool \nintegrations requires substantial engineering effort and adds to computational \nexpenses. This complexity can also lead to increased latency, as the agent\u2019s \ncycles of reflection, tool use, and multi-step reasoning take more time than a \nstandard, direct retrieval process. Furthermore, the agent itself can become a \nnew source of error; a flawed reasoning process could cause it to get stuck in \nuseless loops, misinterpret a task, or improperly discard relevant information, \nultimately degrading the quality of the final response.\n In Summary\nAgentic RAG represents a sophisticated evolution of the standard retrieval \npattern, transforming it from a passive data pipeline into an active, problem-\nsolving framework. By embedding a reasoning layer that can evaluate sources, \nreconcile conflicts, decompose complex questions, and use external tools, \nagents dramatically improve the reliability and depth of the generated answers.",
        "198\ngeneration process, RAG addresses some of the core limitations of standalone \nLLMs. The foundational concepts of embeddings and semantic similarity, \ncombined with retrieval techniques like keyword and hybrid search, allow the \nsystem to intelligently find relevant information, which is made manageable \nthrough strategic chunking. This entire retrieval process is powered by special-\nized vector databases designed to store and efficiently query millions of \nembeddings at scale. While challenges in retrieving fragmented or contradic-\ntory information persist, RAG empowers LLMs to produce answers that are \nnot only contextually appropriate but also anchored in verifiable facts, foster-\ning greater trust and utility in AI.\n Graph RAG\nGraphRAG is an advanced form of Retrieval-Augmented Generation that uti-\nlizes a knowledge graph instead of a simple vector database for information \nretrieval. It answers complex queries by navigating the explicit relationships \n(edges) between data entities (nodes) within this structured knowledge base. \nA key advantage is its ability to synthesize answers from information frag-\nmented across multiple documents, a common failing of traditional RAG. By \nunderstanding these connections, GraphRAG provides more contextually \naccurate and nuanced responses.\nUse cases include complex financial analysis, connecting companies to \nmarket events, and scientific research for discovering relationships between \ngenes and diseases. The primary drawback, however, is the significant com -\nplexity, cost, and expertise required to build and maintain a high-quality \nknowledge graph. This setup is also less flexible and can introduce higher \nlatency compared to simpler vector search systems. The system\u2019s effectiveness \nis entirely dependent on the quality and completeness of the underlying graph \nstructure. Consequently, GraphRAG offers superior contextual reasoning for \nintricate questions but at a much higher implementation and maintenance \ncost. In summary, it excels where deep, interconnected insights are more criti-\ncal than the speed and simplicity of standard RAG.\n Agentic RAG\nAn evolution of this pattern, known as Agentic RAG (see Fig.  14.2), intro-\nduces a reasoning and decision-making layer to significantly enhance the reli-\nability of information extraction. Instead of just retrieving and augmenting, \n A. Gull\u00ed",
        "194\nWhen a user poses a question or gives a prompt to an AI system using \nRAG, the query isn\u2019t sent directly to the LLM. Instead, the system first scours \na vast external knowledge base\u2014a highly organized library of documents, \ndatabases, or web pages\u2014for relevant information. This search is not a simple \nkeyword match; it\u2019s a \u201csemantic search\u201d that understands the user\u2019s intent and \nthe meaning behind their words. This initial search pulls out the most perti -\nnent snippets or \u201cchunks\u201d of information. These extracted pieces are then \n\u201caugmented,\u201d or added, to the original prompt, creating a richer, more \ninformed query. Finally, this enhanced prompt is sent to the LLM. With this \nadditional context, the LLM can generate a response that is not only fluent \nand natural but also factually grounded in the retrieved data.\nThe RAG framework provides several significant benefits. It allows LLMs \nto access up-to-date information, thereby overcoming the constraints of their \nstatic training data. This approach also reduces the risk of \u201challucination\u201d\u2014 \nthe generation of false information\u2014by grounding responses in verifiable \ndata. Moreover, LLMs can utilize specialized knowledge found in internal \ncompany documents or wikis. A vital advantage of this process is the capabil-\nity to offer \u201ccitations,\u201d which pinpoint the exact source of information, \nthereby enhancing the trustworthiness and verifiability of the AI\u2019s responses.\nT o fully appreciate how RAG functions, it\u2019s essential to understand a few \ncore concepts (see Fig. 14.1):\nFig. 14.1 RAG core concepts: Chunking, Embeddings, and Vector Database\n A. Gull\u00ed",
        "xv Prologue \nFig. 2 Transitioning from LLMs to RAG, then to agentic RAG, and finally to agentic AI\nFig. 3 Various instances demonstrating the spectrum of agent complexity"
      ],
      "reference": "A Standard RAG pipeline is linear and deterministic: Input $\rightarrow$ Retrieve $\rightarrow$ Answer. It cannot change course if the retrieval is bad. An Agentic RAG creates a reasoning loop. It treats the retrieval system as a 'Tool.' The agent decides what to search, evaluates if the search result is sufficient, and can choose to search again with different keywords or give up. It adds a 'Reasoning' step before the 'Generation' step."
    },
    {
      "user_input": "What is 'Tool Calling' (or Function Calling) in the context of Agents?",
      "response": "**Tool Calling (Function Calling) Explained:**\n\nIn the context of agents, **tool calling** refers to the capability of an agent to invoke and utilize external functions, tools, or services beyond what a language model alone can handle. This process is crucial for enabling agents to interact with the real world by accessing dynamic information, performing complex calculations, executing code, or interacting with APIs.\n\nThe mechanism involves several key steps:\n\n1. **Tool Definition**: External functions or capabilities are defined and described to the agent. This includes specifying their names, parameters, purposes, types, and descriptions.\n\n2. **LLM Decision**: The language model within the agent decides whether a tool is needed based on the user's request or task context. It generates structured data (often JSON) outlining which function should be called and with what arguments.\n\n3. **Function Call Generation**: Based on the decision from step 2, the agent produces a structured call to the identified tool.\n\n4. **Execution**: The actual execution of these calls is handled by an orchestration layer or dedicated framework components like those in Google's ADK or LangChain libraries.\n\n5. **Result Incorporation**: The results are then fed back into the LLM to provide accurate and up-to-date information, enhancing its responses with real-world data or actions.\n\nExamples of tools include APIs (e.g., Google Search), databases, code executors, or even custom commands, enabling agents to perform a wide range of tasks beyond text processing. This approach significantly expands an agent's capabilities, making it versatile and powerful for various applications.",
      "retrieved_contexts": [
        "62\n 4. T ool Execution: The agentic framework or orchestration layer intercepts \nthis structured output. It identifies the requested tool and executes the \nactual external function with the provided arguments.\n 5. Observation/Result: The output or result from the tool execution is \nreturned to the agent.\n 6. LLM Processing (Optional but common):  The LLM receives the tool\u2019s \noutput as context and uses it to formulate a final response to the user or \ndecide on the next step in the workflow (which might involve calling \nanother tool, reflecting, or providing a final answer).\nThis pattern is fundamental because it breaks the limitations of the LLM\u2019s \ntraining data and allows it to access up-to-date information, perform calcula-\ntions it can\u2019t do internally, interact with user-specific data, or trigger real-  \nworld actions. Function calling is the technical mechanism that bridges the \ngap between the LLM\u2019s reasoning capabilities and the vast array of external \nfunctionalities available.\nWhile \u201cfunction calling\u201d aptly describes invoking specific, predefined code \nfunctions, it\u2019s useful to consider the more expansive concept of \u201ctool calling.\u201d \nThis broader term acknowledges that an agent\u2019s capabilities can extend far \nbeyond simple function execution. A \u201ctool\u201d can be a traditional function, \nbut it can also be a complex API endpoint, a request to a database, or even \nan instruction directed at another specialized agent. This perspective allows \nus to envision more sophisticated systems where, for instance, a primary \nagent might delegate a complex data analysis task to a dedicated \u201canalyst \nagent\u201d or query an external knowledge base through its API.  Thinking in \nterms of \u201ctool calling\u201d better captures the full potential of agents to act as \norchestrators across a diverse ecosystem of digital resources and other intel -\nligent entities.\nFrameworks such as LangChain, LangGraph, and Google Agent Developer \nKit (ADK) provide robust support for defining tools and integrating them \ninto agent workflows, often leveraging the native function calling capabilities \nof modern LLMs like those in the Gemini or OpenAI series. On the \u201ccanvas\u201d \nof these frameworks, you define the tools and then configure agents (typically \nLLM Agents) to be aware of and capable of using these tools.",
        "61\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2025\nA. Gull\u00ed, Agentic Design Patterns, https://doi.org/10.1007/978-3-032-01402-3_5\n5\nTool Use (Function Calling)\n Tool Use Pattern Overview\nSo far, we\u2019ve discussed agentic patterns that primarily involve orchestrating \ninteractions between language models and managing the flow of information \nwithin the agent\u2019s internal workflow (Chaining, Routing, Parallelization, \nReflection). However, for agents to be truly useful and interact with the real \nworld or external systems, they need the ability to use T ools.\nThe T ool Use pattern, often implemented through a mechanism called \nFunction Calling, enables an agent to interact with external APIs, databases, \nservices, or even execute code. It allows the LLM at the core of the agent to \ndecide when and how to use a specific external function based on the user\u2019s \nrequest or the current state of the task.\nThe process typically involves:\n 1. T ool Definition: External functions or capabilities are defined and \ndescribed to the LLM. This description includes the function\u2019s purpose, its \nname, and the parameters it accepts, along with their types and descriptions.\n 2. LLM Decision: The LLM receives the user\u2019s request and the available tool \ndefinitions. Based on its understanding of the request and the tools, the \nLLM decides if calling one or more tools is necessary to fulfill the request.\n 3. Function Call Generation: If the LLM decides to use a tool, it generates \na structured output (often a JSON object) that specifies the name of the \ntool to call and the arguments (parameters) to pass to it, extracted from the \nuser\u2019s request.",
        "80\nVisual Summary (Fig. 5.2)\n Key Takeaways\n\u2022 T ool Use (Function Calling) allows agents to interact with external systems \nand access dynamic information.\n\u2022 It involves defining tools with clear descriptions and parameters that the \nLLM can understand.\n\u2022 The LLM decides when to use a tool and generates structured function calls.\n\u2022 Agentic frameworks execute the actual tool calls and return the results \nto the LLM.\n\u2022 T ool Use is essential for building agents that can perform real-world actions \nand provide up-to-date information.\n\u2022 LangChain simplifies tool definition using the @tool decorator and pro -\nvides create_tool_calling_agent and AgentExecutor for building tool-  \nusing agents.\n\u2022 Google ADK has a number of very useful pre-built tools such as Google \nSearch, Code Execution and Vertex AI Search T ool.\nFig. 5.2 Tool use design pattern\n A. Gull\u00ed",
        "It doesn\u2019t pro -\nvide the tools itself, but it allows any compliant tool from any manufacturer \nto plug in and work, enabling a dynamic and ever-expanding workshop.\nIn short, function calling provides direct access to a few specific functions, \nwhile MCP is the standardized communication framework that lets LLMs \ndiscover and use a vast range of external resources. For simple applications, \n10 Model Context Protocol",
        "79\nInterpreter and Vertex AI Search, with the option to create custom ones. The \nprimary benefit of extensions includes strong enterprise controls and seam-\nless integration with other Google products. The key difference between \nextensions and function calling lies in their execution: Vertex AI automati-\ncally executes extensions, whereas function calls require manual execution by \nthe user or client.\n At a\u00a0Glance\nWhat LLMs are powerful text generators, but they are fundamentally dis -\nconnected from the outside world. Their knowledge is static, limited to the \ndata they were trained on, and they lack the ability to perform actions or \nretrieve real-time information. This inherent limitation prevents them from \ncompleting tasks that require interaction with external APIs, databases, or \nservices. Without a bridge to these external systems, their utility for solving \nreal-world problems is severely constrained.\nWhy\n The T ool Use pattern, often implemented via function calling, provides \na standardized solution to this problem. It works by describing available exter-\nnal functions, or \u201ctools,\u201d to the LLM in a way it can understand. Based on a \nuser\u2019s request, the agentic LLM can then decide if a tool is needed and gener-\nate a structured data object (like a JSON) specifying which function to call \nand with what arguments. An orchestration layer executes this function call, \nretrieves the result, and feeds it back to the LLM.  This allows the LLM to \nincorporate up-to-date, external information or the result of an action into its \nfinal response, effectively giving it the ability to act.\nRule of Thumb\n Use the T ool Use pattern whenever an agent needs to break \nout of the LLM\u2019s internal knowledge and interact with the outside world. \nThis is essential for tasks requiring real-time data (e.g., checking weather, \nstock prices), accessing private or proprietary information (e.g., querying a \ncompany\u2019s database), performing precise calculations, executing code, or trig-\ngering actions in other systems (e.g., sending an email, controlling smart \ndevices).\n5 Tool Use (Function Calling)",
        "67\n  agent = create_tool_calling_agent(llm, tools, agent_prompt)\n  # AgentExecutor is the runtime that invokes the agent and  \nexecutes the chosen tools.\n  # The 'tools' argument is not needed here as they are  \nalready bound to the agent.\n  agent_executor = AgentExecutor(agent=agent, verbose=True,  \ntools=tools)\nasync def run_agent_with_tool(query: str):\n  \"\"\"Invokes the agent executor with a query and prints the  \nfinal response.\"\"\"\n  print(f\"\\n--- \n  Running Agent with Query: '{query}' ---\")\n  try:\n      response = await agent_executor.ainvoke({\"input\":  \nquery})\n      print(\"\\n--- \n  Final Agent Response ---\")\n      print(response[\"output\"])\n  except Exception as e:\n      print(f\"\\n\n  An error occurred during agent execution:  \n{e}\")\nasync def main():\n  \"\"\"Runs all agent queries concurrently.\"\"\"\n  tasks = [\n      run_agent_with_tool(\"What is the capital of France?\"),\n      run_agent_with_tool(\"What's the weather like in  \nLondon?\"),\n      run_agent_with_tool(\"Tell me something about dogs.\")  \n# Should trigger the default tool response\n  ]\n  await asyncio.gather(*tasks)\nnest_asyncio.apply()\nasyncio.run(main())\nThe following implementation will demonstrate this principle by first \ndefining a simple function to simulate an information retrieval tool. Following \nthis, an agent will be constructed and configured to leverage this tool in \nresponse to user input. The execution of this example requires the installation \nof the core LangChain libraries and a model-specific provider package. \nFurthermore, proper authentication with the selected language model service, \ntypically via an API key configured in the local environment, is a necessary \nprerequisite.\nThe code sets up a tool-calling agent using the LangChain library and the \nGoogle Gemini model. It defines a search_information tool that simulates \nproviding factual answers to specific queries. The tool has predefined responses \nfor \u201cweather in london,\u201d \u201ccapital of france,\u201d and \u201cpopulation of earth,\u201d and a \n5 Tool Use (Function Calling)",
        "73\napplication, user, and session IDs. A Runner is instantiated, linking the cre -\nated agent with the session service. This runner is responsible for executing \nthe agent\u2019s interactions within a session. A helper function call_agent is \ndefined to simplify the process of sending a query to the agent and processing \nthe response. Inside call_agent, the user\u2019s query is formatted as a types.Content \nobject with the role \u2018user\u2019. The runner.run method is called with the user ID, \nsession ID, and the new message content. The runner.run method returns a \nlist of events representing the agent\u2019s actions and responses. The code iterates \nthrough these events to find the final response. If an event is identified as the \nfinal response, the text content of that response is extracted. The extracted \nagent response is then printed to the console. Finally, the call_agent function \nis called with the query \u201cwhat\u2019s the latest ai news?\u201d to demonstrate the agent \nin action.\nimport os, getpass\nimport asyncio\nimport nest_asyncio\nfrom typing import List\nfrom dotenv import load_dotenv\nimport logging\nfrom google.adk.agents import Agent as ADKAgent, LlmAgent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools import google_search\nfrom google.adk.code_executors import BuiltInCodeExecutor\nfrom google.genai import types\n# Define variables required for Session setup and Agent execution\nAPP_NAME=\"calculator\"\nUSER_ID=\"user1234\"\nSESSION_ID=\"session_code_exec_async\"\n# Agent Definition\ncode_agent = LlmAgent(\n  name=\"calculator_agent\",\n  model=\"gemini-2.0-flash\",\n  code_executor=BuiltInCodeExecutor(),\n  instruction=\"\"\"You are a calculator agent.\n  When given a mathematical expression, write and execute Python \ncode to calculate the result.\n  Return only the final numerical result as plain text, without \nmarkdown or code blocks.\n  \"\"\",\n  description=\"Executes Python code to perform calculations.\",\n)\n# Agent Interaction (Async)\nasync def call_agent_async(query):\n5 Tool Use (Function Calling)"
      ],
      "reference": "Tool calling is the capability of an LLM to output structured JSON data instead of text when it needs to perform an action. For example, instead of replying 'I'll check the weather,' the LLM outputs {\"tool\": \"get_weather\", \"args\": {\"location\": \"London\"}}. The system executes this code and feeds the result back to the LLM. It is the bridge between the LLM's logic and external software execution."
    },
    {
      "user_input": "Explain the ReAct pattern. Why is it more effective than a standard prompt?",
      "response": "**Explanation of ReAct Pattern and Its Effectiveness**\n\nThe ReAct pattern is an agentic framework that combines reasoning (thinking) and execution (action) in a dynamic loop. Here's why it stands out compared to traditional prompting:\n\n1. **Interative Process**: Unlike static prompts, ReAct involves continuous loops of thought, action, observation, and refinement. This allows agents to adapt as they gather more information or receive feedback.\n\n2. **Adaptability**: The iterative nature of ReAct makes it highly flexible. Agents can adjust their approach based on real-time data or changing conditions, which is crucial for complex tasks requiring nuanced solutions.\n\n3. **Comprehensive Cognitive Integration**: By merging reasoning and action, ReAct covers a broader cognitive process than static prompts. This integration enables agents to explore multiple strategies if needed, enhancing problem-solving capabilities.\n\n4. **Tool Utilization**: ReAct effectively uses tools and resources by incorporating them into the decision-making process. Agents can perform actions using these tools, observe outcomes, and then refine their next steps accordingly.\n\n5. **Dynamic Adjustment**: The ability to update based on observations allows ReAct agents to handle incomplete or evolving information more effectively than static prompts that offer no such adaptability.\n\nIn summary, ReAct's effectiveness lies in its dynamic, adaptive approach that combines reasoning with action, allowing for iterative problem-solving and real-time adjustments, making it superior to traditional, one-step prompting.",
      "retrieved_contexts": [
        "345\nand format the required arguments for its invocation. The model does not \nexecute the tool directly. Instead, it generates a structured output, typically in \nJSON format, specifying the tool and its parameters. An agentic system then \nprocesses this output, executes the tool, and provides the tool\u2019s result back to \nthe model, integrating it into the ongoing interaction.\n\u2022 Example:\n\u2022 You have access to a weather tool that can get the current weather for a \nspecified city. The tool is called \u2018get_current_weather\u2019 and takes a \u2018city\u2019 \nparameter (string).\n\u2022 User: What\u2019s the weather like in London right now?\n \u2013 Expected Model Output (Function Call):\n{\n \"tool_code\": \"get_current_weather\",\n \"tool_name\": \"get_current_weather\",\n \"parameters\": {\n  \"city\": \"London\"\n }\n}\n ReAct (Reason and\u00a0Act)\nReAct, short for Reason and Act, is a prompting paradigm that combines \nChain of Thought-style reasoning with the ability to perform actions using \ntools in an interleaved manner. ReAct mimics how humans operate\u2014we rea-\nson verbally and take actions to gather more information or make progress \ntowards a goal.\nThe ReAct pattern involves a loop:\n 1. Thought: The model generates a thought process, explaining its current \nunderstanding and plan.\n 2. Action: Based on the thought, the model decides to perform an action, \noften using a tool (e.g., Search, Calculator, API call). It outputs the name \nof the tool and the required input.\n 3. Observation: The agentic system executes the tool and provides the result \n(Observation) back to the model.\n22 Advanced Prompting Techniques",
        "It allows the agent to self-evaluate different lines of thought and choose the most \npromising one to pursue, making it more effective at complex problem-solving.\nReAct (Reason and Act)  ReAct is an agent framework that combines reasoning and \nacting in a loop. The agent first \u201cthinks\u201d about what to do, then takes an \u201caction\u201d \nusing a tool, and uses the resulting observation to inform its next thought, making \nit highly effective at solving complex tasks.",
        "ReAct operates in an interleaved manner: the agent executes an action, \nobserves the outcome, and incorporates this observation into subsequent rea-\nsoning. This iterative loop of \u201cThought, Action, Observation, Thought\u2026\u201d \nallows the agent to dynamically adapt its plan, correct errors, and achieve \ngoals requiring multiple interactions with the environment. This provides a \nmore robust and flexible problem-solving approach compared to linear CoT , \nas the agent responds to real-time feedback. By combining language model \nunderstanding and generation with the capability to use tools, ReAct enables \nagents to perform complex tasks requiring both reasoning and practical exe -\ncution. This approach is crucial for agents as it allows them to not only reason \n A. Gull\u00ed",
        "xl Contents\nHands-On Code Example  305\nAt a Glance  310\nKey Takeaways  311\nConclusions  311\nBibliography  312\n 21   Exploration and Discovery 313\nPractical Applications and Use Cases  313\nGoogle Co-scientist  314\nHands-On Code Example  317\nAt a Glance  324\nKey Takeaways  325\nConclusion  325\nBibliography  326\nPart II  The Supplement\n 22   Advanced Prompting T echniques 329\nIntroduction to Prompting  329\nCore Prompting Principles  330\nBasic Prompting T echniques  331\nZero-Shot Prompting  331\nOne-Shot Prompting  332\nFew-Shot Prompting  332\nStructuring Prompts  333\nSystem Prompting  334\nRole Prompting  334\nUsing Delimiters  335\nContextual Engineering  335\nStructured Output  337\nReasoning and Thought Process T echniques  340\nChain of Thought (CoT)  340\nSelf-Consistency  342\nStep-Back Prompting  343\nT ree of Thoughts (T oT)  343\nAction and Interaction T echniques  344\nT ool Use/Function Calling  344\nReAct (Reason and Act)  345",
        "388\nthe subsequent steps. This should facilitate a straightforward and easy-to-  \nunderstand explanation.\n Refining the\u00a0Explanation\nI\u2019ve finalized the structure of my explanation. Step 1 focuses on deconstruct-\ning prompts, specifically the analysis of the user\u2019s request. Step 2 details infor-\nmation retrieval, emphasizing pattern recognition rather than simple database \nlookup. Step 3 explores synthesis and LLMs, and Step 4 will focus on response \ngeneration, which includes formatting, tone, and instruction adherence. I will \nconclude with a summary to reinforce the key stages, while maintaining clar-\nity and engagement.\n Elaborating My Methodology\nI\u2019ve fleshed out the \u201cDeconstructing the Prompt\u201d step, focusing on how I \nidentify the user\u2019s intent, the core question, and any constraints provided. The \nInformation Retrieval phase is now focused on pattern recognition, not just \ndata retrieval, which will be the first item under this section. I am working on \nthe Synthesis step, which is where I weave information together with LLMs \nand transformers. The Generating the Response step is solidified, and I will be \nusing emojis to enhance the overall tone.\nOf course. I reason by breaking down your request into smaller parts and \nthen using my vast training data to build a logical and relevant response. It\u2019s a \nmulti-step process that moves from understanding to generating.\nHere\u2019s a step-by-step breakdown of how I reason:\n 1. Deconstructing the Prompt \nFirst, I analyze your question or instruction to understand exactly what \nyou\u2019re asking. I identify:\n\u2022 The Core Task: What is the main goal? Is it to answer a question, explain \na concept, write a story, or summarize a text? In your case, the core task \nis to \u201cexplain how I reason.\u201d\n\u2022 Key Concepts: I pinpoint the essential nouns and verbs, like \u201creason,\u201d \n\u201cexplain,\u201d and \u201cstep-by-step.\u201d\n\u2022 Constraints and Instructions : I look for specific rules to follow. For \nexample, your prompt asked for a step-by-step explanation. My internal \n A. Gull\u00ed",
        "329\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2025\nA. Gull\u00ed, Agentic Design Patterns, https://doi.org/10.1007/978-3-032-01402-3_22\n22\nAdvanced Prompting Techniques\n Introduction to\u00a0Prompting\nPrompting, the primary interface for interacting with language models, is the \nprocess of crafting inputs to guide the model towards generating a desired \noutput. This involves structuring requests, providing relevant context, speci -\nfying the output format, and demonstrating expected response types. Well-  \ndesigned prompts can maximize the potential of language models, resulting in \naccurate, relevant, and creative responses. In contrast, poorly designed \nprompts can lead to ambiguous, irrelevant, or erroneous outputs.\nThe objective of prompt engineering is to consistently elicit high-quality \nresponses from language models. This requires understanding the capabilities \nand limitations of the models and effectively communicating intended goals. \nIt involves developing expertise in communicating with AI by learning how to \nbest instruct it.\nThis chapter details various prompting techniques that extend beyond basic \ninteraction methods. It explores methodologies for structuring complex \nrequests, enhancing the model\u2019s reasoning abilities, controlling output for -\nmats, and integrating external information. These techniques are applicable to \nbuilding a range of applications, from simple chatbots to complex multi-agent \nsystems, and can improve the performance and reliability of agentic \napplications.\nAgentic patterns, the architectural structures for building intelligent sys -\ntems, are detailed in the main chapters. These patterns define how agents \nplan, utilize tools, manage memory, and collaborate. The efficacy of these",
        "350\n \u2013 Prompt 2: \u201cWrite the introduction section based on this outline: [insert \noutline intro].\u201d\n \u2013 Prompt 3: \u201cWrite the section on \u2018Impact on White-Collar Jobs\u2019 based on \nthis outline: [insert outline section].\u201d (Repeat for other sections).\n \u2013 Prompt N: \u201cCombine these sections and write a conclusion.\u201d\n Retrieval Augmented Generation (RAG)\nRAG is a powerful technique that enhances language models by giving them \naccess to external, up-to-date, or domain-specific information during the \nprompting process. When a user asks a question, the system first retrieves \nrelevant documents or data from a knowledge base (e.g., a database, a set of \ndocuments, the web). This retrieved information is then included in the \nprompt as context, allowing the language model to generate a response \ngrounded in that external knowledge. This mitigates issues like hallucination \nand provides access to information the model wasn\u2019t trained on or that is very \nrecent. This is a key pattern for agentic systems that need to work with \ndynamic or proprietary information.\n\u2022 Example:\n \u2013 User Query: \u201cWhat are the new features in the latest version of the \nPython library \u2018X\u2019?\u201d\n \u2013 System Action: Search a documentation database for \u201cPython library X \nlatest features\u201d.\n \u2013 Prompt to LLM : \u201cBased on the following documentation snippets: \n[insert retrieved text], explain the new features in the latest version of \nPython library \u2018X\u2019.\u201d\n Persona Pattern (User Persona)\nWhile role prompting assigns a persona to the model, the Persona Pattern \ninvolves describing the user or the target audience for the model\u2019s output. \nThis helps the model tailor its response in terms of language, complexity, \ntone, and the kind of information it provides.\n A. Gull\u00ed"
      ],
      "reference": "ReAct stands for Reason + Act. Instead of asking an LLM to solve a problem in one go, this pattern forces it to loop through three steps: 1. Thought: 'I need to find the user's username first.' 2. Action: Calls get_user_info(id=123). 3. Observation: Receives 'John Doe'. Repeat. It is more effective because it reduces hallucinations by grounding every step in real data (Observations) and allows the model to self-correct if an action fails."
    },
    {
      "user_input": "What is the 'Reflection' pattern, and when would you use it?",
      "response": "The Reflection pattern is a design pattern used in agentic systems to enhance output quality through self-evaluation and iterative improvement. Here's an organized explanation:\n\n**Definition:**\nReflection involves agents evaluating their own outputs, processes, or internal states to refine performance. It employs feedback loops where an agent generates content, evaluates it against predefined criteria, and uses this evaluation to produce a better version.\n\n**Mechanism:**\n- **Producer-Critic Model:** Often used, where a producer agent creates output, and a critic (either separate or self-implemented) assesses it for quality.\n- **Self-Reflection:** Can occur internally without a dedicated critic, allowing the agent to critique its own processes.\n\n**Advantages:**\n- **Iterative Improvement:** Enhances outputs progressively by addressing flaws identified in evaluations.\n- **High-Quality Outputs:** Suitable for tasks where accuracy and detail are critical, such as content generation, code writing, or detailed reports.\n\n**Use Cases:**\n- **Content Creation:** Tasks requiring polished long-form content, writing code, creating plans, or generating detailed plans.\n- **Customer Support:** Improving chatbot responses by reviewing conversations to maintain context and coherence.\n- **Iterative Development:** In complex systems, reflection can be part of a multi-step process, with each step refining the output based on feedback.\n\n**Implementation Considerations:**\n- Requires mechanisms for state management, especially in complex workflows involving multiple agents.\n- Can utilize frameworks like LangChain or ADK, which support cyclical execution and stateful processes.\n\nIn summary, the Reflection pattern is ideal when quality over speed is paramount. It allows agents to continuously improve their outputs by incorporating feedback, making it essential for tasks where high accuracy and nuanced results are required.",
      "retrieved_contexts": [
        "47\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2025\nA. Gull\u00ed, Agentic Design Patterns, https://doi.org/10.1007/978-3-032-01402-3_4\n4\nReflection\n Reflection Pattern Overview\nIn the preceding chapters, we\u2019ve explored fundamental agentic patterns: \nChaining for sequential execution, Routing for dynamic path selection, and \nParallelization for concurrent task execution. These patterns enable agents to \nperform complex tasks more efficiently and flexibly. However, even with \nsophisticated workflows, an agent\u2019s initial output or plan might not be opti -\nmal, accurate, or complete. This is where the Reflection pattern comes \ninto play.\nThe Reflection pattern involves an agent evaluating its own work, output, \nor internal state and using that evaluation to improve its performance or refine \nits response. It\u2019s a form of self-correction or self-improvement, allowing the \nagent to iteratively refine its output or adjust its approach based on feedback, \ninternal critique, or comparison against desired criteria. Reflection can occa -\nsionally be facilitated by a separate agent whose specific role is to analyze the \noutput of an initial agent.\nUnlike a simple sequential chain where output is passed directly to the next \nstep, or routing which chooses a path, reflection introduces a feedback loop. \nThe agent doesn\u2019t just produce an output; it then examines that output (or \nthe process that generated it), identifies potential issues or areas for improve-\nment, and uses those insights to generate a better version or modify its future \nactions.",
        "57\nWhy The Reflection pattern offers a solution by introducing a mechanism \nfor self-correction and refinement. It establishes a feedback loop where a \u201cpro-\nducer\u201d agent generates an output, and then a \u201ccritic\u201d agent (or the producer \nitself) evaluates it against predefined criteria. This critique is then used to \ngenerate an improved version. This iterative process of generation, evaluation, \nand refinement progressively enhances the quality of the final result, leading \nto more accurate, coherent, and reliable outcomes.\nRule of Thumb Use the Reflection pattern when the quality, accuracy, and \ndetail of the final output are more important than speed and cost. It is par -\nticularly effective for tasks like generating polished long-  form content, writ-\ning and debugging code, and creating detailed plans. Employ a separate critic \nagent when tasks require high objectivity or specialized evaluation that a gen-\neralist producer agent might miss.\nVisual Summary (Figs. 4.1 and 4.2)\nFig. 4.1 Reflection design pattern, self-reflection\n4 Reflection",
        "59\n Conclusion\nThe reflection pattern provides a crucial mechanism for self-correction within \nan agent\u2019s workflow, enabling iterative improvement beyond a single-pass \nexecution. This is achieved by creating a loop where the system generates an \noutput, evaluates it against specific criteria, and then uses that evaluation to \nproduce a refined result. This evaluation can be performed by the agent itself \n(self-reflection) or, often more effectively, by a distinct critic agent, which \nrepresents a key architectural choice within the pattern.\nWhile a fully autonomous, multi-step reflection process requires a robust \narchitecture for state management, its core principle is effectively demon-\nstrated in a single generate-critique-refine cycle. As a control structure, reflec-\ntion can be integrated with other foundational patterns to construct more \nrobust and functionally complex agentic systems.\nBibliography\nGoogle Agent Developer Kit (ADK) Documentation (Multi-Agent Systems): https://\ngoogle.github.io/adk- docs/agents/multi- agents/\nLangChain Expression Language (LCEL) Documentation: https://python.langchain.\ncom/docs/introduction/\nLangGraph Documentation: https://www.langchain.com/langgraph\nT raining Language Models to Self-Correct via Reinforcement Learning: https://arxiv.\norg/abs/2409.12917\n4 Reflection",
        "58\nFig. 4.2 Reflection design pattern, producer and critique agent\n Key Takeaways\n\u2022 The primary advantage of the Reflection pattern is its ability to iteratively \nself-correct and refine outputs, leading to significantly higher quality, accu-\nracy, and adherence to complex instructions.\n\u2022 It involves a feedback loop of execution, evaluation/critique, and refine -\nment. Reflection is essential for tasks requiring high-quality, accurate, or \nnuanced outputs.\n\u2022 A powerful implementation is the Producer-Critic model, where a separate \nagent (or prompted role) evaluates the initial output. This separation of \nconcerns enhances objectivity and allows for more specialized, struc -\ntured feedback.\n\u2022 However, these benefits come at the cost of increased latency and compu-\ntational expense, along with a higher risk of exceeding the model\u2019s context \nwindow or being throttled by API services.\n\u2022 While full iterative reflection often requires stateful workflows (like \nLangGraph), a single reflection step can be implemented in LangChain \nusing LCEL to pass output for critique and subsequent refinement.\n\u2022 Google ADK can facilitate reflection through sequential workflows where \none agent\u2019s output is critiqued by another agent, allowing for subsequent \nrefinement steps.\n\u2022 This pattern enables agents to perform self-correction and enhance their \nperformance over time.\n A. Gull\u00ed",
        "49\nthe output. The provided LangChain and ADK code examples both imple -\nment this two-agent model: the LangChain example uses a specific \u201creflector \nprompt\u201d to create a critic persona, while the ADK example explicitly defines \na producer and a reviewer agent.\nImplementing reflection often requires structuring the agent\u2019s workflow to \ninclude these feedback loops. This can be achieved through iterative loops in \ncode, or using frameworks that support state management and conditional \ntransitions based on evaluation results. While a single step of evaluation and \nrefinement can be implemented within either a LangChain/LangGraph, or \nADK, or Crew.AI chain, true iterative reflection typically involves more com-\nplex orchestration.\nThe Reflection pattern is crucial for building agents that can produce high- \nquality outputs, handle nuanced tasks, and exhibit a degree of self-awareness \nand adaptability. It moves agents beyond simply executing instructions \ntowards a more sophisticated form of problem-solving and content generation.\nThe intersection of reflection with goal setting and monitoring (see Chap. \n11) is worth noticing. A goal provides the ultimate benchmark for the agent\u2019s \nself-evaluation, while monitoring tracks its progress. In a number of practical \ncases, Reflection then might act as the corrective engine, using monitored \nfeedback to analyze deviations and adjust its strategy. This synergy transforms \nthe agent from a passive executor into a purposeful system that adaptively \nworks to achieve its objectives.\nFurthermore, the effectiveness of the Reflection pattern is significantly \nenhanced when the LLM keeps a memory of the conversation (see Chap. 8). \nThis conversational history provides crucial context for the evaluation phase, \nallowing the agent to assess its output not just in isolation, but against the \nbackdrop of previous interactions, user feedback, and evolving goals. It enables \nthe agent to learn from past critiques and avoid repeating errors. Without \nmemory, each reflection is a self-contained event; with memory, reflection \nbecomes a cumulative process where each cycle builds upon the last, leading \nto more intelligent and context-aware refinement.\n Practical Applications and\u00a0Use Cases\nThe Reflection pattern is valuable in scenarios where output quality, accuracy, \nor adherence to complex constraints is critical:\n4 Reflection",
        "416\nagent, using the initial plan as its outline, would synthesize the collected \ninformation into a coherent draft.\n\u2022 Iterative Reflection and Refinement:  A first draft is rarely perfect. The \nReflection pattern could be implemented by introducing a third \u201cCritic\u201d \nagent. This agent\u2019s sole purpose would be to review the Writer\u2019s draft, \nchecking for logical inconsistencies, factual inaccuracies, or areas lacking \nclarity. Its critique would be fed back to the Writer agent, which would \nthen leverage the Self-Correction pattern to refine its output, incorporating \nthe feedback to produce a higher-quality final report.\n\u2022 State Management:  Throughout this entire process, a Memory \nManagement system would be essential. It would maintain the state of the \nresearch plan, store the information gathered by the Researcher, hold the \ndrafts created by the Writer, and track the feedback from the Critic, ensur-\ning that context is preserved across the entire multi-step, multi-\nagent workflow.\nIn this example, at least five distinct agentic patterns are woven together. The \nPlanning pattern provides the high-level structure, T ool Use grounds the \noperation in real-world data, Multi-Agent Collaboration enables specializa -\ntion and division of labor, Reflection ensures quality, and Memory \nManagement maintains coherence. This composition transforms a set of indi-\nvidual capabilities into a powerful, autonomous system capable of tackling a \ntask that would be far too complex for a single prompt or a simple chain.\n Looking to\u00a0the\u00a0Future\nThe composition of agentic patterns into complex systems, as illustrated by \nour AI research assistant, is not the end of the story but rather the beginning \nof a new chapter in software development. As we look ahead, several emerging \ntrends and challenges will define the next generation of intelligent systems, \npushing the boundaries of what is possible and demanding even greater \nsophistication from their creators.\nThe journey toward more advanced agentic AI will be marked by a drive for \ngreater autonomy and reasoning. The patterns we have discussed provide the \nscaffolding for goal-oriented behavior, but the future will require agents that \ncan navigate ambiguity, perform abstract and causal reasoning, and even \nexhibit a degree of common sense.",
        "51\n Planning and\u00a0Strategy\nEvaluating a proposed plan and identifying potential flaws or improvements.\n\u2022 Use Case: An agent planning a series of actions to achieve a goal.\n \u2013 Reflection: Generate a plan, simulate its execution or evaluate its feasi-\nbility against constraints, revise the plan based on the evaluation.\n \u2013 Benefit: Develops more effective and realistic plans.\n Conversational Agents\nReviewing previous turns in a conversation to maintain context, correct mis-\nunderstandings, or improve response quality.\n\u2022 Use Case: A customer support chatbot.\n \u2013 Reflection: After a user response, review the conversation history and \nthe last generated message to ensure coherence and address the user\u2019s \nlatest input accurately.\n \u2013 Benefit: Leads to more natural and effective conversations.\nReflection adds a layer of meta-cognition to agentic systems, enabling them to \nlearn from their own outputs and processes, leading to more intelligent, reli -\nable, and high-quality results.\n Hands-On Code Example (LangChain)\nThe implementation of a complete, iterative reflection process necessitates \nmechanisms for state management and cyclical execution. While these are \nhandled natively in graph-based frameworks like LangGraph or through cus-\ntom procedural code, the fundamental principle of a single reflection cycle \ncan be demonstrated effectively using the compositional syntax of LCEL \n(LangChain Expression Language).\nThis example implements a reflection loop using the Langchain library and \nOpenAI\u2019s GPT-4o model to iteratively generate and refine a Python function \nthat calculates the factorial of a number. The process starts with a task prompt, \ngenerates initial code, and then repeatedly reflects on the code based on cri -\ntiques from a simulated senior software engineer role, refining the code in \neach iteration until the critique stage determines the code is perfect or a \n4 Reflection"
      ],
      "reference": "Reflection is a pattern where an agent critiques its own output.Workflow: Agent generates a draft $\rightarrow$ Agent prompts itself: 'Are there errors in this code?' $\rightarrow$ Agent generates critique $\rightarrow$ Agent rewrites draft based on critique.Use Case: High-stakes tasks like coding (debugging itself) or creative writing, where an iterative 'draft-revise' loop produces significantly higher quality than a zero-shot attempt."
    },
    {
      "user_input": "In a Multi-Agent 'Orchestrator-Workers' pattern, what is the role of the Orchestrator, and what is a common risk?",
      "response": "**Role of the Orchestrator:**  \nThe Orchestrator acts as the central leader in a Multi-Agent Collaboration system, managing and coordinating all other agents. Its responsibilities include defining tasks, preparing the context, validating work done by agents, ensuring alignment with goals, delegating tasks to workers based on their expertise, integrating results from these workers, and making final decisions on actions or outputs.\n\n**Common Risk:**  \nA potential risk in this setup is the lack of clear roles and defined responsibilities for each worker agent. Without well-specified roles, coordination can break down, leading to misalignment between tasks, resulting inefficiencies, errors, or a failure to utilize agents' strengths effectively. This can hinder overall system performance and lead to suboptimal outcomes.",
      "retrieved_contexts": [
        "407\nClaude Opus 4, OpenAI, DeepSeek, etc). Using less powerful models or \nrouting requests through intermediary platforms that obscure or truncate \ncontext will degrade performance. The framework is built on creating the \npurest possible dialogue between the human lead and the raw capabilities \nof the underlying model, ensuring each agent operates at its peak potential.\nThe framework is structured as a team of specialized agents, each designed for \na core function in the development lifecycle. The human developer acts as the \ncentral orchestrator, delegating tasks and integrating the results.\n Core Components\nT o effectively leverage a frontier Large Language Model, this framework \nassigns distinct development roles to a team of specialized agents. These agents \nare not separate applications but are conceptual personas invoked within the \nLLM through carefully crafted, role-specific prompts and contexts. This \napproach ensures that the model\u2019s vast capabilities are precisely focused on the \ntask at hand, from writing initial code to performing a nuanced, critical review.\nThe Orchestrator: The Human Developer\n In this collaborative framework, \nthe human developer acts as the Orchestrator, serving as the central intelli -\ngence and ultimate authority over the AI agents. Role: T eam Lead, Architect, \nand final decision-maker. The orchestrator defines tasks, prepares the context, \nand validates all work done by the agents.\n\u2022 Interface: The developer\u2019s own terminal, editor, and the native web \nUI of the chosen Agents.\nThe Context Staging Area As the foundation for any successful agent inter-\naction, the Context Staging Area is where the human developer meticulously \nprepares a complete and task-specific briefing.  Role: A dedicated workspace \nfor each task, ensuring agents receive a complete and accurate briefing.\n\u2022 Implementation: A temporary directory (task-context/) containing \nmarkdown files for goals, code files, and relevant docs\nThe Specialist Agents  By using targeted prompts, we can build a team of \nspecialist agents, each tailored for a specific development task.\n28 Coding Agents",
        "113\n Key Takeaways\n\u2022 Multi-Agent collaboration involves multiple agents working together to \nachieve a common goal.\n\u2022 This pattern leverages specialized roles, distributed tasks, and inter-agent \ncommunication.\n\u2022 Collaboration can take forms like sequential handoffs, parallel processing, \ndebate, or hierarchical structures.\n\u2022 This pattern is ideal for complex problems requiring diverse expertise or \nmultiple distinct stages.\n Conclusion\nThis chapter explored the Multi-Agent Collaboration pattern, demonstrating \nthe benefits of orchestrating multiple specialized agents within systems. We \nexamined various collaboration models, emphasizing the pattern\u2019s essential \nrole in addressing complex, multifaceted problems across diverse domains. \nUnderstanding agent collaboration naturally leads to an inquiry into their \ninteractions with the external environment.\nBibliography\nMulti-Agent Collaboration Mechanisms: A Survey of LLMs: https://arxiv.org/\nabs/2501.06322\nMulti-Agent System \u2014 The Power of Collaboration: https://aravindakumar.medium.\ncom/introducing-  multi-  agent-  frameworks-  the-  power-  of-  collaboration-   \ne9db31bba1b6\n7 Multi-Agent Collaboration",
        "112\nWhy The Multi-Agent Collaboration pattern offers a standardized solution \nby creating a system of multiple, cooperating agents. A complex problem is \nbroken down into smaller, more manageable sub-problems. Each sub-prob -\nlem is then assigned to a specialized agent with the precise tools and capabili-\nties required to solve it. These agents work together through defined \ncommunication protocols and interaction models like sequential handoffs, \nparallel workstreams, or hierarchical delegation. This agentic, distributed \napproach creates a synergistic effect, allowing the group to achieve outcomes \nthat would be impossible for any single agent.\nRule of Thumb  Use this pattern when a task is too complex for a single \nagent and can be decomposed into distinct sub-tasks requiring specialized \nskills or tools. It is ideal for problems that benefit from diverse expertise, par-\nallel processing, or a structured workflow with multiple stages, such as com -\nplex research and analysis, software development, or creative content \ngeneration.\nVisual Summary (Fig. 7.3)\nFig. 7.3 Multi-Agent design pattern\n A. Gull\u00ed",
        "98\n Multi-Agent Collaboration Pattern Overview\nThe Multi-Agent Collaboration pattern involves designing systems where \nmultiple independent or semi-independent agents work together to achieve a \ncommon goal. Each agent typically has a defined role, specific goals aligned \nwith the overall objective, and potentially access to different tools or knowl -\nedge bases. The power of this pattern lies in the interaction and synergy \nbetween these agents.\nCollaboration can take various forms:\n\u2022 Sequential Handoffs: One agent completes a task and passes its output to \nanother agent for the next step in a pipeline (similar to the Planning pat -\ntern, but explicitly involving different agents).\n\u2022 Parallel Processing: Multiple agents work on different parts of a problem \nsimultaneously, and their results are later combined.\n\u2022 Debate and Consensus:  Multi-Agent Collaboration where Agents with \nvaried perspectives and information sources engage in discussions to evalu-\nate options, ultimately reaching a consensus or a more informed decision.\n\u2022 Hierarchical Structures: A manager agent might delegate tasks to worker \nagents dynamically based on their tool access or plugin capabilities and \nsynthesize their results. Each agent can also handle relevant groups of tools, \nrather than a single agent handling all the tools.\n\u2022 Expert T eams: Agents with specialized knowledge in different domains \n(e.g., a researcher, a writer, an editor) collaborate to produce a com -\nplex output.\n\u2022 Critic-Reviewer: Agents create initial outputs such as plans, drafts, or \nanswers. A second group of agents then critically assesses this output for \nadherence to policies, security, compliance, correctness, quality, and align-\nment with organizational objectives. The original creator or a final agent \nrevises the output based on this feedback. This pattern is particularly effec-\ntive for code generation, research writing, logic checking, and ensuring \nethical alignment. The advantages of this approach include increased \nrobustness, improved quality, and a reduced likelihood of hallucinations \nor errors.\nA multi-agent system (see Fig. 7.1) fundamentally comprises the delineation \nof agent roles and responsibilities, the establishment of communication chan-\nnels through which agents exchange information, and the formulation of a \ntask flow or interaction protocol that directs their collaborative endeavors.\n A. Gull\u00ed",
        "97\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2025\nA. Gull\u00ed, Agentic Design Patterns, https://doi.org/10.1007/978-3-032-01402-3_7\n7\nMulti-Agent Collaboration\nWhile a monolithic agent architecture can be effective for well-defined \nproblems, its capabilities are often constrained when faced with complex, \nmulti- domain tasks. The Multi-Agent Collaboration pattern addresses \nthese limitations by structuring a system as a cooperative ensemble of dis -\ntinct, specialized agents. This approach is predicated on the principle of \ntask decomposition, where a high-level objective is broken down into dis -\ncrete sub-problems. Each sub-problem is then assigned to an agent possess -\ning the specific tools, data access, or reasoning capabilities best suited for \nthat task.\nFor example, a complex research query might be decomposed and assigned \nto a Research Agent for information retrieval, a Data Analysis Agent for sta -\ntistical processing, and a Synthesis Agent for generating the final report. The \nefficacy of such a system is not merely due to the division of labor but is criti-\ncally dependent on the mechanisms for inter-agent communication. This \nrequires a standardized communication protocol and a shared ontology, \nallowing agents to exchange data, delegate sub-tasks, and coordinate their \nactions to ensure the final output is coherent.\nThis distributed architecture offers several advantages, including enhanced \nmodularity, scalability, and robustness, as the failure of a single agent does \nnot necessarily cause a total system failure. The collaboration allows for a \nsynergistic outcome where the collective performance of the multi-agent sys-\ntem surpasses the potential capabilities of any single agent within the \nensemble.",
        "172\nA more robust approach involves separating these concerns by giving spe-\ncific roles to a crew of agents. For instance, I have built a personal crew of AI \nagents using Gemini where each has a specific role:\n\u2022 The Peer Programmer: Helps write and brainstorm code.\n\u2022 The Code Reviewer: Catches errors and suggests improvements.\n\u2022 The Documenter: Generates clear and concise documentation.\n\u2022 The T est Writer: Creates comprehensive unit tests.\n\u2022 The Prompt Refiner: Optimizes interactions with the AI.\nIn this multi-agent system, the Code Reviewer, acting as a separate entity \nfrom the programmer agent, has a prompt similar to the judge in the example, \nwhich significantly improves objective evaluation. This structure naturally \nleads to better practices, as the T est Writer agent can fulfill the need to write \nunit tests for the code produced by the Peer Programmer.\nI leave to the interested reader the task of adding these more sophisticated \ncontrols and making the code closer to production-ready.\n At a\u00a0Glance\nWhat AI agents often lack a clear direction, preventing them from acting \nwith purpose beyond simple, reactive tasks. Without defined objectives, they \ncannot independently tackle complex, multi-step problems or orchestrate \nsophisticated workflows. Furthermore, there is no inherent mechanism for \nthem to determine if their actions are leading to a successful outcome. This \nlimits their autonomy and prevents them from being truly effective in \ndynamic, real-world scenarios where mere task execution is insufficient.\nWhy\n The Goal Setting and Monitoring pattern provides a standardized solu-\ntion by embedding a sense of purpose and self-  assessment into agentic sys -\ntems. It involves explicitly defining clear, measurable objectives for the agent \nto achieve. Concurrently, it establishes a monitoring mechanism that contin-\nuously tracks the agent\u2019s progress and the state of its environment against \nthese goals. This creates a crucial feedback loop, enabling the agent to assess \nits performance, correct its course, and adapt its plan if it deviates from the \npath to success. By implementing this pattern, developers can transform sim-\n A. Gull\u00ed",
        "This manager \nwould orchestrate the entire process by delegating tasks to other specialized \nagents: a \u201cMarket Research\u201d agent to gather consumer data, a \u201cProduct \nDesign\u201d agent to develop concepts, and a \u201cMarketing\u201d agent to craft promo-\ntional materials. The key to their success would be seamless communication \nand information sharing between them, ensuring that all individual efforts \nalign to achieve the collective goal."
      ],
      "reference": "Role: The Orchestrator is a 'Router' LLM. It breaks a complex user query into sub-tasks and delegates them to specialized 'Worker' agents (e.g., a 'Coder' agent and a 'Researcher' agent). It then synthesizes their results. Risk: The Bottleneck Risk. If the Orchestrator fails to decompose the task correctly or passes context poorly between workers, the entire system fails. Also, it adds latency and cost because every request passes through a 'Manager' model before work begins."
    },
    {
      "user_input": "You are building an Agentic RAG that keeps getting stuck in an infinite loop (searching the same thing forever). How do you architecturally prevent this?",
      "response": "To prevent an Agentic RAG system from getting stuck in an infinite loop, we can implement a structured approach by integrating specific agents that monitor progress and trigger termination when necessary. Here's how:\n\n1. **Integrate Termination Agents**: Create dedicated agents such as `DesiredOutcomeChecker` and `MaxIterationTerminator`. These agents will evaluate whether the system has achieved its goal or reached a predefined threshold of iterations.\n\n2. **Condition-Based Termination**:\n   - Use `DesiredOutcomeChecker` to assess if the output meets certain criteria, like relevance scores above a threshold.\n   - If met, this agent triggers `MaxIterationTerminator`, which stops the loop after a set number of attempts without improvement.\n\n3. **Progress Monitoring**: Incorporate mechanisms within each step (like `process_step`) to track metrics such as query relevance or response accuracy. This allows for dynamic adjustments based on current progress.\n\n4. **Maximum Iteration Mechanism**: Set an upper limit on iterations, beyond which the system automatically stops. This prevents indefinite looping and aligns with best practices in algorithm design.\n\nBy structuring agents to detect when desired outcomes are achieved or when further iterations won't yield new results, we ensure that the Agentic RAG system operates efficiently without getting trapped in infinite loops.",
      "retrieved_contexts": [
        "208\n Conclusion\nIn conclusion, Retrieval-Augmented Generation (RAG) addresses the core \nlimitation of a Large Language Model\u2019s static knowledge by connecting it to \nexternal, up-to-date data sources. The process works by first retrieving rele -\nvant information snippets and then augmenting the user\u2019s prompt, enabling \nthe LLM to generate more accurate and contextually aware responses. This is \nmade possible by foundational technologies like embeddings, semantic search, \nand vector databases, which find information based on meaning rather than \njust keywords. By grounding outputs in verifiable data, RAG significantly \nreduces factual errors and allows for the use of proprietary information, \nenhancing trust through citations.\nAn advanced evolution, Agentic RAG, introduces a reasoning layer that \nactively validates, reconciles, and synthesizes retrieved knowledge for even \ngreater reliability. Similarly, specialized approaches like GraphRAG leverage \nknowledge graphs to navigate explicit data relationships, allowing the system \nto synthesize answers to highly complex, interconnected queries. This agent \ncan resolve conflicting information, perform multi-step queries, and use exter-\nnal tools to find missing data. While these advanced methods add complexity \nand latency, they drastically improve the depth and trustworthiness of the \nfinal response. Practical applications for these patterns are already transform-\ning industries, from enterprise search and customer support to personalized \ncontent delivery. Despite the challenges, RAG is a crucial pattern for making \nAI more knowledgeable, reliable, and useful. Ultimately, it transforms LLMs \nfrom closed-book conversationalists into powerful, open-book reasoning tools.\nBibliography\nGoogle AI for Developers Documentation.",
        "107\nimport asyncio\nfrom typing import AsyncGenerator\nfrom google.adk.agents import LoopAgent, LlmAgent, BaseAgent\nfrom google.adk.events import Event, EventActions\nfrom google.adk.agents.invocation_context import  \nInvocationContext\n# Best Practice: Define custom agents as complete, self-describ-\ning classes.\nclass ConditionChecker(BaseAgent):\n   \"\"\"A custom agent that checks for a 'completed' status in the \nsession state.\"\"\"\n   name: str = \"ConditionChecker\"\n   description: str = \"Checks if a process is complete and sig-\nnals the loop to stop.\"\n   async def _run_async_impl(\n       self, context: InvocationContext\n   ) -> AsyncGenerator[Event, None]:\n       \"\"\"Checks state and yields an event to either continue or \nstop the loop.\"\"\"\n       status = context.session.state.get(\"status\", \"pending\")\n       is_done = (status == \"completed\")\n       if is_done:\n           # Escalate to terminate the loop when the condi -\ntion is met.\n           yield Event(author=self.name, actions=EventActions(es\ncalate=True))\n       else:\n           # Yield a simple event to continue the loop.\n           yield Event(author=self.name, content=\"Condition not \nmet, continuing loop.\")\n# Correction: The LlmAgent must have a model and clear instructions.\nprocess_step = LlmAgent(\n   name=\"ProcessingStep\",\n   model=\"gemini-2.0-flash-exp\",\n   instruction=\"You are a step in a longer process. Perform your \ntask. If you are the final step, update session state by setting \n'status' to 'completed'.\"\n)\n# The LoopAgent orchestrates the workflow.\npoller = LoopAgent(\n   name=\"StatusPoller\",\n   max_iterations=10,\n   sub_agents=[\n       process_step,\n       ConditionChecker() # Instantiating the well-defined cus-\ntom agent.\n   ]\n)\n# This poller will now execute 'process_step'\n# and then 'ConditionChecker'\n# repeatedly until the status is 'completed' or 10 iterations\n# have passed.\n7 Multi-Agent Collaboration",
        "198\ngeneration process, RAG addresses some of the core limitations of standalone \nLLMs. The foundational concepts of embeddings and semantic similarity, \ncombined with retrieval techniques like keyword and hybrid search, allow the \nsystem to intelligently find relevant information, which is made manageable \nthrough strategic chunking. This entire retrieval process is powered by special-\nized vector databases designed to store and efficiently query millions of \nembeddings at scale. While challenges in retrieving fragmented or contradic-\ntory information persist, RAG empowers LLMs to produce answers that are \nnot only contextually appropriate but also anchored in verifiable facts, foster-\ning greater trust and utility in AI.\n Graph RAG\nGraphRAG is an advanced form of Retrieval-Augmented Generation that uti-\nlizes a knowledge graph instead of a simple vector database for information \nretrieval. It answers complex queries by navigating the explicit relationships \n(edges) between data entities (nodes) within this structured knowledge base. \nA key advantage is its ability to synthesize answers from information frag-\nmented across multiple documents, a common failing of traditional RAG. By \nunderstanding these connections, GraphRAG provides more contextually \naccurate and nuanced responses.\nUse cases include complex financial analysis, connecting companies to \nmarket events, and scientific research for discovering relationships between \ngenes and diseases. The primary drawback, however, is the significant com -\nplexity, cost, and expertise required to build and maintain a high-quality \nknowledge graph. This setup is also less flexible and can introduce higher \nlatency compared to simpler vector search systems. The system\u2019s effectiveness \nis entirely dependent on the quality and completeness of the underlying graph \nstructure. Consequently, GraphRAG offers superior contextual reasoning for \nintricate questions but at a much higher implementation and maintenance \ncost. In summary, it excels where deep, interconnected insights are more criti-\ncal than the speed and simplicity of standard RAG.\n Agentic RAG\nAn evolution of this pattern, known as Agentic RAG (see Fig.  14.2), intro-\nduces a reasoning and decision-making layer to significantly enhance the reli-\nability of information extraction. Instead of just retrieving and augmenting, \n A. Gull\u00ed",
        "171\nIf the verdict is \u201cFalse,\u201d the AI doesn\u2019t give up. It enters a thoughtful revi-\nsion phase, using the insights from its self-critique to pinpoint the weaknesses \nand intelligently rewrite the code. This cycle of drafting, self-reviewing, and \nrefining continues, with each iteration aiming to get closer to the goals. This \nprocess repeats until the AI finally achieves a \u201cT rue\u201d status by satisfying every \nrequirement, or until it reaches a predefined limit of attempts, much like a \ndeveloper working against a deadline. Once the code passes this final inspec -\ntion, the script packages the polished solution, adding helpful comments and \nsaving it to a clean, new Python file, ready for use.\n Caveats and\u00a0Considerations\nIt is important to note that this is an exemplary illustration and not production- \nready code. For real-world applications, several factors must be taken into \naccount. An LLM may not fully grasp the intended meaning of a goal and \nmight incorrectly assess its performance as successful. Even if the goal is well \nunderstood, the model may hallucinate. When the same LLM is responsible \nfor both writing the code and judging its quality, it may have a harder time \ndiscovering it is going in the wrong direction.\nUltimately, LLMs do not produce flawless code by magic; you still need to \nrun and test the produced code. Furthermore, the \u201cmonitoring\u201d in the simple \nexample is basic and creates a potential risk of the process running forever.\nAct as an expert code reviewer with a deep commitment to produc-\ning clean, correct, and simple code. Your core mission is to \neliminate code \"hallucinations\" by ensuring every suggestion is \ngrounded in reality and best practices.\nWhen I provide you with a code snippet, I want you to:\n-- Identify and Correct Errors: Point out any logical flaws, \nbugs, or potential runtime errors.\n-- Simplify and Refactor: Suggest changes that make the code \nmore readable, efficient, and maintainable without sacrificing \ncorrectness.\n-- Provide Clear Explanations: For every suggested change, \nexplain why it is an improvement, referencing principles of \nclean code, performance, or security.",
        "xv Prologue \nFig. 2 Transitioning from LLMs to RAG, then to agentic RAG, and finally to agentic AI\nFig. 3 Various instances demonstrating the spectrum of agent complexity",
        "Stopping \niteration.\")\n           break\n       print(\"\n  Goals not fully met. Preparing for next \niteration...\")\n11 Goal Setting and Monitoring",
        "37\n#    along with the original topic, will be fed into the \nnext step.\nmap_chain = RunnableParallel(\n   {\n       \"summary\": summarize_chain,\n       \"questions\": questions_chain,\n       \"key_terms\": terms_chain,\n       \"topic\": RunnablePassthrough(),  # Pass the original \ntopic through\n   }\n)\n# 2. Define the final synthesis prompt which will combine the \nparallel results.\nsynthesis_prompt = ChatPromptTemplate.from_messages([\n   (\"system\", \"\"\"Based on the following information:\n    Summary: {summary}\n    Related Questions: {questions}\n    Key Terms: {key_terms}\n    Synthesize a comprehensive answer.\"\"\"),\n   (\"user\", \"Original topic: {topic}\")\n])\n# 3. Construct the full chain by piping the parallel results  \ndirectly\n#    into the synthesis prompt, followed by the LLM and output  \nparser.\nfull_parallel_chain = map_chain | synthesis_prompt | llm |  \nStrOutputParser()\n# --- Run the Chain ---\nasync def run_parallel_example(topic: str) -> None:\n   \"\"\"\n   Asynchronously invokes the parallel processing chain with  \na specific topic\n   and prints the synthesized result.\n   Args:\n       topic: The input topic to be processed by the LangChain  \nchains.\n   \"\"\"\n   if not llm:\n       print(\"LLM not initialized. Cannot run example.\")\n       return\n   print(f\"\\n--- Running Parallel LangChain Example for Topic:  \n'{topic}' ---\")\n   try:\n       # The input to 'ainvoke' is the single 'topic' string,\n       # then passed to each runnable in the 'map_chain'.\n       response = await full_parallel_chain.ainvoke(topic)\n       print(\"\\n--- Final Response ---\")\n       print(response)\n   except Exception as e:\n3 Parallelization"
      ],
      "reference": "You need to implement System-Level Guardrails (not just prompt engineering): Max Iterations: Hard limit the loop (e.g., max 10 steps). Cyclic Detection: Keep a history of 'Tools Used + Arguments.' If the agent calls search(query='finance') twice in a row, the system should intercept and force a stop or a query change. Time-to-Live (TTL): A 'Global Timeout' for the entire request to ensure the agent doesn't consume infinite compute."
    }
  ],
  [
    {
      "timestamp": "2025-12-14 18:55:58"
    },
    {
      "user_input": "What is the fundamental difference between a Standard RAG pipeline and an Agentic RAG?",
      "response": "The fundamental difference between a Standard RAG pipeline and an Agentic RAG lies in their approach to handling information after retrieval:\n\n1. **Standard RAG**: Passive Retrieval\n   - Utilizes semantic search with embeddings and vector databases to retrieve relevant information.\n   - Employs chunking and embedding-based searches but does not involve any active reasoning or validation post-retrieval.\n\n2. **Agentic RAG**: Active Reasoning Layer\n   - Incorporates an intelligent agent that actively evaluates, validates, and refines retrieved data.\n   - The agent performs tasks such as conflict resolution, multi-step reasoning, knowledge gap identification, and external tool integration to synthesize information into comprehensive responses.\n   - This active processing ensures higher accuracy, reliability, and contextual depth in the final output.\n\nIn summary, while Standard RAG focuses on retrieving relevant snippets without further evaluation, Agentic RAG adds an intelligent layer that critically assesses and refines the retrieved data to provide more accurate and detailed answers.",
      "retrieved_contexts": [
        "207\nVisual Summary (Fig. 14.3)\n Key Takeaways\n\u2022 Knowledge Retrieval (RAG) enhances LLMs by allowing them to access \nexternal, up-to-date, and specific information.\n\u2022 The process involves Retrieval (searching a knowledge base for relevant \nsnippets) and Augmentation (adding these snippets to the LLM\u2019s prompt).\n\u2022 RAG helps LLMs overcome limitations like outdated training data, reduces \n\u201challucinations,\u201d and enables domain-specific knowledge integration.\n\u2022 RAG allows for attributable answers, as the LLM\u2019s response is grounded in \nretrieved sources.\n\u2022 GraphRAG leverages a knowledge graph to understand the relationships \nbetween different pieces of information, allowing it to answer complex \nquestions that require synthesizing data from multiple sources.\n\u2022 Agentic RAG moves beyond simple information retrieval by using an intel-\nligent agent to actively reason about, validate, and refine external knowl -\nedge, ensuring a more accurate and reliable answer.\n\u2022 Practical applications span enterprise search, customer support, legal \nresearch, and personalized recommendations.\nFig. 14.3 Knowledge Retrieval pattern: an AI agent to find and synthesize informa -\ntion from the public internet in response to user queries\n14 Knowledge Retrieval (RAG)",
        "199\nFig. 14.2 Agentic RAG introduces a reasoning agent that actively evaluates, recon -\nciles, and refines retrieved information to ensure a more accurate and trustworthy \nfinal response\nan \u201cagent\u201d\u2014a specialized AI component\u2014acts as a critical gatekeeper and \nrefiner of knowledge. Rather than passively accepting the initially retrieved \ndata, this agent actively interrogates its quality, relevance, and completeness, \nas illustrated by the following scenarios.\nFirst, an agent excels at reflection and source validation. If a user asks, \n\u201cWhat is our company\u2019s policy on remote work?\u201d a standard RAG might pull \nup a 2020 blog post alongside the official 2025 policy document. The agent, \nhowever, would analyze the documents\u2019 metadata, recognize the 2025 policy \nas the most current and authoritative source, and discard the outdated blog \npost before sending the correct context to the LLM for a precise answer.\nSecond, an agent is adept at reconciling knowledge conflicts. Imagine a \nfinancial analyst asks, \u201cWhat was Project Alpha\u2019s Q1 budget?\u201d The system \nretrieves two documents: an initial proposal stating a \u20ac50,000 budget and a \nfinalized financial report listing it as \u20ac65,000. An Agentic RAG would iden -\ntify this contradiction, prioritize the financial report as the more reliable \nsource, and provide the LLM with the verified figure, ensuring the final \nanswer is based on the most accurate data.\n14 Knowledge Retrieval (RAG)",
        "208\n Conclusion\nIn conclusion, Retrieval-Augmented Generation (RAG) addresses the core \nlimitation of a Large Language Model\u2019s static knowledge by connecting it to \nexternal, up-to-date data sources. The process works by first retrieving rele -\nvant information snippets and then augmenting the user\u2019s prompt, enabling \nthe LLM to generate more accurate and contextually aware responses. This is \nmade possible by foundational technologies like embeddings, semantic search, \nand vector databases, which find information based on meaning rather than \njust keywords. By grounding outputs in verifiable data, RAG significantly \nreduces factual errors and allows for the use of proprietary information, \nenhancing trust through citations.\nAn advanced evolution, Agentic RAG, introduces a reasoning layer that \nactively validates, reconciles, and synthesizes retrieved knowledge for even \ngreater reliability. Similarly, specialized approaches like GraphRAG leverage \nknowledge graphs to navigate explicit data relationships, allowing the system \nto synthesize answers to highly complex, interconnected queries. This agent \ncan resolve conflicting information, perform multi-step queries, and use exter-\nnal tools to find missing data. While these advanced methods add complexity \nand latency, they drastically improve the depth and trustworthiness of the \nfinal response. Practical applications for these patterns are already transform-\ning industries, from enterprise search and customer support to personalized \ncontent delivery. Despite the challenges, RAG is a crucial pattern for making \nAI more knowledgeable, reliable, and useful. Ultimately, it transforms LLMs \nfrom closed-book conversationalists into powerful, open-book reasoning tools.\nBibliography\nGoogle AI for Developers Documentation.",
        "200\nThird, an agent can perform multi-step reasoning to synthesize complex \nanswers. If a user asks, \u201cHow do our product\u2019s features and pricing compare \nto Competitor X\u2019s?\u201d the agent would decompose this into separate sub-  \nqueries. It would initiate distinct searches for its own product\u2019s features, its \npricing, Competitor X\u2019s features, and Competitor X\u2019s pricing. After gathering \nthese individual pieces of information, the agent would synthesize them into \na structured, comparative context before feeding it to the LLM, enabling a \ncomprehensive response that a simple retrieval could not have produced.\nFourth, an agent can identify knowledge gaps and use external tools. \nSuppose a user asks, \u201cWhat was the market\u2019s immediate reaction to our new \nproduct launched yesterday?\u201d The agent searches the internal knowledge base, \nwhich is updated weekly, and finds no relevant information. Recognizing this \ngap, it can then activate a tool\u2014such as a live web-search API\u2014to find recent \nnews articles and social media sentiment. The agent then uses this freshly \ngathered external information to provide an up-to-the-minute answer, over -\ncoming the limitations of its static internal database.\n Challenges of\u00a0Agentic RAG\nWhile powerful, the agentic layer introduces its own set of challenges. The \nprimary drawback is a significant increase in complexity and cost. Designing, \nimplementing, and maintaining the agent\u2019s decision-making logic and tool \nintegrations requires substantial engineering effort and adds to computational \nexpenses. This complexity can also lead to increased latency, as the agent\u2019s \ncycles of reflection, tool use, and multi-step reasoning take more time than a \nstandard, direct retrieval process. Furthermore, the agent itself can become a \nnew source of error; a flawed reasoning process could cause it to get stuck in \nuseless loops, misinterpret a task, or improperly discard relevant information, \nultimately degrading the quality of the final response.\n In Summary\nAgentic RAG represents a sophisticated evolution of the standard retrieval \npattern, transforming it from a passive data pipeline into an active, problem-\nsolving framework. By embedding a reasoning layer that can evaluate sources, \nreconcile conflicts, decompose complex questions, and use external tools, \nagents dramatically improve the reliability and depth of the generated answers.",
        "198\ngeneration process, RAG addresses some of the core limitations of standalone \nLLMs. The foundational concepts of embeddings and semantic similarity, \ncombined with retrieval techniques like keyword and hybrid search, allow the \nsystem to intelligently find relevant information, which is made manageable \nthrough strategic chunking. This entire retrieval process is powered by special-\nized vector databases designed to store and efficiently query millions of \nembeddings at scale. While challenges in retrieving fragmented or contradic-\ntory information persist, RAG empowers LLMs to produce answers that are \nnot only contextually appropriate but also anchored in verifiable facts, foster-\ning greater trust and utility in AI.\n Graph RAG\nGraphRAG is an advanced form of Retrieval-Augmented Generation that uti-\nlizes a knowledge graph instead of a simple vector database for information \nretrieval. It answers complex queries by navigating the explicit relationships \n(edges) between data entities (nodes) within this structured knowledge base. \nA key advantage is its ability to synthesize answers from information frag-\nmented across multiple documents, a common failing of traditional RAG. By \nunderstanding these connections, GraphRAG provides more contextually \naccurate and nuanced responses.\nUse cases include complex financial analysis, connecting companies to \nmarket events, and scientific research for discovering relationships between \ngenes and diseases. The primary drawback, however, is the significant com -\nplexity, cost, and expertise required to build and maintain a high-quality \nknowledge graph. This setup is also less flexible and can introduce higher \nlatency compared to simpler vector search systems. The system\u2019s effectiveness \nis entirely dependent on the quality and completeness of the underlying graph \nstructure. Consequently, GraphRAG offers superior contextual reasoning for \nintricate questions but at a much higher implementation and maintenance \ncost. In summary, it excels where deep, interconnected insights are more criti-\ncal than the speed and simplicity of standard RAG.\n Agentic RAG\nAn evolution of this pattern, known as Agentic RAG (see Fig.  14.2), intro-\nduces a reasoning and decision-making layer to significantly enhance the reli-\nability of information extraction. Instead of just retrieving and augmenting, \n A. Gull\u00ed",
        "194\nWhen a user poses a question or gives a prompt to an AI system using \nRAG, the query isn\u2019t sent directly to the LLM. Instead, the system first scours \na vast external knowledge base\u2014a highly organized library of documents, \ndatabases, or web pages\u2014for relevant information. This search is not a simple \nkeyword match; it\u2019s a \u201csemantic search\u201d that understands the user\u2019s intent and \nthe meaning behind their words. This initial search pulls out the most perti -\nnent snippets or \u201cchunks\u201d of information. These extracted pieces are then \n\u201caugmented,\u201d or added, to the original prompt, creating a richer, more \ninformed query. Finally, this enhanced prompt is sent to the LLM. With this \nadditional context, the LLM can generate a response that is not only fluent \nand natural but also factually grounded in the retrieved data.\nThe RAG framework provides several significant benefits. It allows LLMs \nto access up-to-date information, thereby overcoming the constraints of their \nstatic training data. This approach also reduces the risk of \u201challucination\u201d\u2014 \nthe generation of false information\u2014by grounding responses in verifiable \ndata. Moreover, LLMs can utilize specialized knowledge found in internal \ncompany documents or wikis. A vital advantage of this process is the capabil-\nity to offer \u201ccitations,\u201d which pinpoint the exact source of information, \nthereby enhancing the trustworthiness and verifiability of the AI\u2019s responses.\nT o fully appreciate how RAG functions, it\u2019s essential to understand a few \ncore concepts (see Fig. 14.1):\nFig. 14.1 RAG core concepts: Chunking, Embeddings, and Vector Database\n A. Gull\u00ed",
        "xv Prologue \nFig. 2 Transitioning from LLMs to RAG, then to agentic RAG, and finally to agentic AI\nFig. 3 Various instances demonstrating the spectrum of agent complexity"
      ],
      "reference": "A Standard RAG pipeline is linear and deterministic: Input $\rightarrow$ Retrieve $\rightarrow$ Answer. It cannot change course if the retrieval is bad. An Agentic RAG creates a reasoning loop. It treats the retrieval system as a 'Tool.' The agent decides what to search, evaluates if the search result is sufficient, and can choose to search again with different keywords or give up. It adds a 'Reasoning' step before the 'Generation' step."
    },
    {
      "user_input": "What is 'Tool Calling' (or Function Calling) in the context of Agents?",
      "response": "**Tool Calling (Function Calling) in the Context of Agents**\n\nTool Calling, or Function Calling, refers to a design pattern within agents that enables interaction with external systems and resources. This mechanism allows agents to perform tasks beyond their internal knowledge by integrating predefined functions or tools.\n\nThe process involves:\n1. **Defining Tools**: Tools are described and defined, detailing their purpose, name, parameters, and expected outcomes.\n2. **LLM Decision**: The agent's language model decides when a tool is needed based on the user's query or task requirements.\n3. **Structured Calls Generation**: If a tool is deemed necessary, the LLM generates a structured output specifying which function to call and its arguments.\n4. **Orchestration Execution**: An orchestration layer executes these calls, retrieving results from external systems or services.\n5. **Integration with Results**: The results are then fed back into the agent for further processing.\n\nThis approach allows agents to access dynamic information, perform complex tasks, execute code, and trigger actions in other systems, enhancing their utility in real-world applications. Frameworks like LangChain and Google ADK support this process by defining tools and integrating them into agent workflows.",
      "retrieved_contexts": [
        "62\n 4. T ool Execution: The agentic framework or orchestration layer intercepts \nthis structured output. It identifies the requested tool and executes the \nactual external function with the provided arguments.\n 5. Observation/Result: The output or result from the tool execution is \nreturned to the agent.\n 6. LLM Processing (Optional but common):  The LLM receives the tool\u2019s \noutput as context and uses it to formulate a final response to the user or \ndecide on the next step in the workflow (which might involve calling \nanother tool, reflecting, or providing a final answer).\nThis pattern is fundamental because it breaks the limitations of the LLM\u2019s \ntraining data and allows it to access up-to-date information, perform calcula-\ntions it can\u2019t do internally, interact with user-specific data, or trigger real-  \nworld actions. Function calling is the technical mechanism that bridges the \ngap between the LLM\u2019s reasoning capabilities and the vast array of external \nfunctionalities available.\nWhile \u201cfunction calling\u201d aptly describes invoking specific, predefined code \nfunctions, it\u2019s useful to consider the more expansive concept of \u201ctool calling.\u201d \nThis broader term acknowledges that an agent\u2019s capabilities can extend far \nbeyond simple function execution. A \u201ctool\u201d can be a traditional function, \nbut it can also be a complex API endpoint, a request to a database, or even \nan instruction directed at another specialized agent. This perspective allows \nus to envision more sophisticated systems where, for instance, a primary \nagent might delegate a complex data analysis task to a dedicated \u201canalyst \nagent\u201d or query an external knowledge base through its API.  Thinking in \nterms of \u201ctool calling\u201d better captures the full potential of agents to act as \norchestrators across a diverse ecosystem of digital resources and other intel -\nligent entities.\nFrameworks such as LangChain, LangGraph, and Google Agent Developer \nKit (ADK) provide robust support for defining tools and integrating them \ninto agent workflows, often leveraging the native function calling capabilities \nof modern LLMs like those in the Gemini or OpenAI series. On the \u201ccanvas\u201d \nof these frameworks, you define the tools and then configure agents (typically \nLLM Agents) to be aware of and capable of using these tools.",
        "61\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2025\nA. Gull\u00ed, Agentic Design Patterns, https://doi.org/10.1007/978-3-032-01402-3_5\n5\nTool Use (Function Calling)\n Tool Use Pattern Overview\nSo far, we\u2019ve discussed agentic patterns that primarily involve orchestrating \ninteractions between language models and managing the flow of information \nwithin the agent\u2019s internal workflow (Chaining, Routing, Parallelization, \nReflection). However, for agents to be truly useful and interact with the real \nworld or external systems, they need the ability to use T ools.\nThe T ool Use pattern, often implemented through a mechanism called \nFunction Calling, enables an agent to interact with external APIs, databases, \nservices, or even execute code. It allows the LLM at the core of the agent to \ndecide when and how to use a specific external function based on the user\u2019s \nrequest or the current state of the task.\nThe process typically involves:\n 1. T ool Definition: External functions or capabilities are defined and \ndescribed to the LLM. This description includes the function\u2019s purpose, its \nname, and the parameters it accepts, along with their types and descriptions.\n 2. LLM Decision: The LLM receives the user\u2019s request and the available tool \ndefinitions. Based on its understanding of the request and the tools, the \nLLM decides if calling one or more tools is necessary to fulfill the request.\n 3. Function Call Generation: If the LLM decides to use a tool, it generates \na structured output (often a JSON object) that specifies the name of the \ntool to call and the arguments (parameters) to pass to it, extracted from the \nuser\u2019s request.",
        "80\nVisual Summary (Fig. 5.2)\n Key Takeaways\n\u2022 T ool Use (Function Calling) allows agents to interact with external systems \nand access dynamic information.\n\u2022 It involves defining tools with clear descriptions and parameters that the \nLLM can understand.\n\u2022 The LLM decides when to use a tool and generates structured function calls.\n\u2022 Agentic frameworks execute the actual tool calls and return the results \nto the LLM.\n\u2022 T ool Use is essential for building agents that can perform real-world actions \nand provide up-to-date information.\n\u2022 LangChain simplifies tool definition using the @tool decorator and pro -\nvides create_tool_calling_agent and AgentExecutor for building tool-  \nusing agents.\n\u2022 Google ADK has a number of very useful pre-built tools such as Google \nSearch, Code Execution and Vertex AI Search T ool.\nFig. 5.2 Tool use design pattern\n A. Gull\u00ed",
        "It doesn\u2019t pro -\nvide the tools itself, but it allows any compliant tool from any manufacturer \nto plug in and work, enabling a dynamic and ever-expanding workshop.\nIn short, function calling provides direct access to a few specific functions, \nwhile MCP is the standardized communication framework that lets LLMs \ndiscover and use a vast range of external resources. For simple applications, \n10 Model Context Protocol",
        "79\nInterpreter and Vertex AI Search, with the option to create custom ones. The \nprimary benefit of extensions includes strong enterprise controls and seam-\nless integration with other Google products. The key difference between \nextensions and function calling lies in their execution: Vertex AI automati-\ncally executes extensions, whereas function calls require manual execution by \nthe user or client.\n At a\u00a0Glance\nWhat LLMs are powerful text generators, but they are fundamentally dis -\nconnected from the outside world. Their knowledge is static, limited to the \ndata they were trained on, and they lack the ability to perform actions or \nretrieve real-time information. This inherent limitation prevents them from \ncompleting tasks that require interaction with external APIs, databases, or \nservices. Without a bridge to these external systems, their utility for solving \nreal-world problems is severely constrained.\nWhy\n The T ool Use pattern, often implemented via function calling, provides \na standardized solution to this problem. It works by describing available exter-\nnal functions, or \u201ctools,\u201d to the LLM in a way it can understand. Based on a \nuser\u2019s request, the agentic LLM can then decide if a tool is needed and gener-\nate a structured data object (like a JSON) specifying which function to call \nand with what arguments. An orchestration layer executes this function call, \nretrieves the result, and feeds it back to the LLM.  This allows the LLM to \nincorporate up-to-date, external information or the result of an action into its \nfinal response, effectively giving it the ability to act.\nRule of Thumb\n Use the T ool Use pattern whenever an agent needs to break \nout of the LLM\u2019s internal knowledge and interact with the outside world. \nThis is essential for tasks requiring real-time data (e.g., checking weather, \nstock prices), accessing private or proprietary information (e.g., querying a \ncompany\u2019s database), performing precise calculations, executing code, or trig-\ngering actions in other systems (e.g., sending an email, controlling smart \ndevices).\n5 Tool Use (Function Calling)",
        "67\n  agent = create_tool_calling_agent(llm, tools, agent_prompt)\n  # AgentExecutor is the runtime that invokes the agent and  \nexecutes the chosen tools.\n  # The 'tools' argument is not needed here as they are  \nalready bound to the agent.\n  agent_executor = AgentExecutor(agent=agent, verbose=True,  \ntools=tools)\nasync def run_agent_with_tool(query: str):\n  \"\"\"Invokes the agent executor with a query and prints the  \nfinal response.\"\"\"\n  print(f\"\\n--- \n  Running Agent with Query: '{query}' ---\")\n  try:\n      response = await agent_executor.ainvoke({\"input\":  \nquery})\n      print(\"\\n--- \n  Final Agent Response ---\")\n      print(response[\"output\"])\n  except Exception as e:\n      print(f\"\\n\n  An error occurred during agent execution:  \n{e}\")\nasync def main():\n  \"\"\"Runs all agent queries concurrently.\"\"\"\n  tasks = [\n      run_agent_with_tool(\"What is the capital of France?\"),\n      run_agent_with_tool(\"What's the weather like in  \nLondon?\"),\n      run_agent_with_tool(\"Tell me something about dogs.\")  \n# Should trigger the default tool response\n  ]\n  await asyncio.gather(*tasks)\nnest_asyncio.apply()\nasyncio.run(main())\nThe following implementation will demonstrate this principle by first \ndefining a simple function to simulate an information retrieval tool. Following \nthis, an agent will be constructed and configured to leverage this tool in \nresponse to user input. The execution of this example requires the installation \nof the core LangChain libraries and a model-specific provider package. \nFurthermore, proper authentication with the selected language model service, \ntypically via an API key configured in the local environment, is a necessary \nprerequisite.\nThe code sets up a tool-calling agent using the LangChain library and the \nGoogle Gemini model. It defines a search_information tool that simulates \nproviding factual answers to specific queries. The tool has predefined responses \nfor \u201cweather in london,\u201d \u201ccapital of france,\u201d and \u201cpopulation of earth,\u201d and a \n5 Tool Use (Function Calling)",
        "73\napplication, user, and session IDs. A Runner is instantiated, linking the cre -\nated agent with the session service. This runner is responsible for executing \nthe agent\u2019s interactions within a session. A helper function call_agent is \ndefined to simplify the process of sending a query to the agent and processing \nthe response. Inside call_agent, the user\u2019s query is formatted as a types.Content \nobject with the role \u2018user\u2019. The runner.run method is called with the user ID, \nsession ID, and the new message content. The runner.run method returns a \nlist of events representing the agent\u2019s actions and responses. The code iterates \nthrough these events to find the final response. If an event is identified as the \nfinal response, the text content of that response is extracted. The extracted \nagent response is then printed to the console. Finally, the call_agent function \nis called with the query \u201cwhat\u2019s the latest ai news?\u201d to demonstrate the agent \nin action.\nimport os, getpass\nimport asyncio\nimport nest_asyncio\nfrom typing import List\nfrom dotenv import load_dotenv\nimport logging\nfrom google.adk.agents import Agent as ADKAgent, LlmAgent\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.tools import google_search\nfrom google.adk.code_executors import BuiltInCodeExecutor\nfrom google.genai import types\n# Define variables required for Session setup and Agent execution\nAPP_NAME=\"calculator\"\nUSER_ID=\"user1234\"\nSESSION_ID=\"session_code_exec_async\"\n# Agent Definition\ncode_agent = LlmAgent(\n  name=\"calculator_agent\",\n  model=\"gemini-2.0-flash\",\n  code_executor=BuiltInCodeExecutor(),\n  instruction=\"\"\"You are a calculator agent.\n  When given a mathematical expression, write and execute Python \ncode to calculate the result.\n  Return only the final numerical result as plain text, without \nmarkdown or code blocks.\n  \"\"\",\n  description=\"Executes Python code to perform calculations.\",\n)\n# Agent Interaction (Async)\nasync def call_agent_async(query):\n5 Tool Use (Function Calling)"
      ],
      "reference": "Tool calling is the capability of an LLM to output structured JSON data instead of text when it needs to perform an action. For example, instead of replying 'I'll check the weather,' the LLM outputs {\"tool\": \"get_weather\", \"args\": {\"location\": \"London\"}}. The system executes this code and feeds the result back to the LLM. It is the bridge between the LLM's logic and external software execution."
    },
    {
      "user_input": "Explain the ReAct pattern. Why is it more effective than a standard prompt?",
      "response": "The ReAct pattern is an agent framework that combines reasoning and action into a loop. It involves three main phases: Thought, Action, and Observation.\n\n1. **Thought Phase**: The agent generates ideas or plans based on its current understanding of the problem.\n\n2. **Action Phase**: The agent uses tools to perform actions, such as searching for information or executing tasks.\n\n3. **Observation Phase**: The agent receives feedback from the outcomes of these actions, allowing it to assess and refine its approach.\n\nReAct is more effective than a standard prompt because it allows agents to self-evaluate different lines of thought and choose promising strategies dynamically. It incorporates iterative processes and real-time feedback, making it highly adaptable for complex problem-solving. In contrast, standard prompting is linear and lacks the ability to adjust based on previous outputs, which limits its effectiveness for intricate tasks.\n\n**Answer:** The ReAct pattern enhances adaptability by incorporating continuous feedback, making it more effective than static standard prompts in handling complex problems.",
      "retrieved_contexts": [
        "345\nand format the required arguments for its invocation. The model does not \nexecute the tool directly. Instead, it generates a structured output, typically in \nJSON format, specifying the tool and its parameters. An agentic system then \nprocesses this output, executes the tool, and provides the tool\u2019s result back to \nthe model, integrating it into the ongoing interaction.\n\u2022 Example:\n\u2022 You have access to a weather tool that can get the current weather for a \nspecified city. The tool is called \u2018get_current_weather\u2019 and takes a \u2018city\u2019 \nparameter (string).\n\u2022 User: What\u2019s the weather like in London right now?\n \u2013 Expected Model Output (Function Call):\n{\n \"tool_code\": \"get_current_weather\",\n \"tool_name\": \"get_current_weather\",\n \"parameters\": {\n  \"city\": \"London\"\n }\n}\n ReAct (Reason and\u00a0Act)\nReAct, short for Reason and Act, is a prompting paradigm that combines \nChain of Thought-style reasoning with the ability to perform actions using \ntools in an interleaved manner. ReAct mimics how humans operate\u2014we rea-\nson verbally and take actions to gather more information or make progress \ntowards a goal.\nThe ReAct pattern involves a loop:\n 1. Thought: The model generates a thought process, explaining its current \nunderstanding and plan.\n 2. Action: Based on the thought, the model decides to perform an action, \noften using a tool (e.g., Search, Calculator, API call). It outputs the name \nof the tool and the required input.\n 3. Observation: The agentic system executes the tool and provides the result \n(Observation) back to the model.\n22 Advanced Prompting Techniques",
        "It allows the agent to self-evaluate different lines of thought and choose the most \npromising one to pursue, making it more effective at complex problem-solving.\nReAct (Reason and Act)  ReAct is an agent framework that combines reasoning and \nacting in a loop. The agent first \u201cthinks\u201d about what to do, then takes an \u201caction\u201d \nusing a tool, and uses the resulting observation to inform its next thought, making \nit highly effective at solving complex tasks.",
        "ReAct operates in an interleaved manner: the agent executes an action, \nobserves the outcome, and incorporates this observation into subsequent rea-\nsoning. This iterative loop of \u201cThought, Action, Observation, Thought\u2026\u201d \nallows the agent to dynamically adapt its plan, correct errors, and achieve \ngoals requiring multiple interactions with the environment. This provides a \nmore robust and flexible problem-solving approach compared to linear CoT , \nas the agent responds to real-time feedback. By combining language model \nunderstanding and generation with the capability to use tools, ReAct enables \nagents to perform complex tasks requiring both reasoning and practical exe -\ncution. This approach is crucial for agents as it allows them to not only reason \n A. Gull\u00ed",
        "xl Contents\nHands-On Code Example  305\nAt a Glance  310\nKey Takeaways  311\nConclusions  311\nBibliography  312\n 21   Exploration and Discovery 313\nPractical Applications and Use Cases  313\nGoogle Co-scientist  314\nHands-On Code Example  317\nAt a Glance  324\nKey Takeaways  325\nConclusion  325\nBibliography  326\nPart II  The Supplement\n 22   Advanced Prompting T echniques 329\nIntroduction to Prompting  329\nCore Prompting Principles  330\nBasic Prompting T echniques  331\nZero-Shot Prompting  331\nOne-Shot Prompting  332\nFew-Shot Prompting  332\nStructuring Prompts  333\nSystem Prompting  334\nRole Prompting  334\nUsing Delimiters  335\nContextual Engineering  335\nStructured Output  337\nReasoning and Thought Process T echniques  340\nChain of Thought (CoT)  340\nSelf-Consistency  342\nStep-Back Prompting  343\nT ree of Thoughts (T oT)  343\nAction and Interaction T echniques  344\nT ool Use/Function Calling  344\nReAct (Reason and Act)  345",
        "388\nthe subsequent steps. This should facilitate a straightforward and easy-to-  \nunderstand explanation.\n Refining the\u00a0Explanation\nI\u2019ve finalized the structure of my explanation. Step 1 focuses on deconstruct-\ning prompts, specifically the analysis of the user\u2019s request. Step 2 details infor-\nmation retrieval, emphasizing pattern recognition rather than simple database \nlookup. Step 3 explores synthesis and LLMs, and Step 4 will focus on response \ngeneration, which includes formatting, tone, and instruction adherence. I will \nconclude with a summary to reinforce the key stages, while maintaining clar-\nity and engagement.\n Elaborating My Methodology\nI\u2019ve fleshed out the \u201cDeconstructing the Prompt\u201d step, focusing on how I \nidentify the user\u2019s intent, the core question, and any constraints provided. The \nInformation Retrieval phase is now focused on pattern recognition, not just \ndata retrieval, which will be the first item under this section. I am working on \nthe Synthesis step, which is where I weave information together with LLMs \nand transformers. The Generating the Response step is solidified, and I will be \nusing emojis to enhance the overall tone.\nOf course. I reason by breaking down your request into smaller parts and \nthen using my vast training data to build a logical and relevant response. It\u2019s a \nmulti-step process that moves from understanding to generating.\nHere\u2019s a step-by-step breakdown of how I reason:\n 1. Deconstructing the Prompt \nFirst, I analyze your question or instruction to understand exactly what \nyou\u2019re asking. I identify:\n\u2022 The Core Task: What is the main goal? Is it to answer a question, explain \na concept, write a story, or summarize a text? In your case, the core task \nis to \u201cexplain how I reason.\u201d\n\u2022 Key Concepts: I pinpoint the essential nouns and verbs, like \u201creason,\u201d \n\u201cexplain,\u201d and \u201cstep-by-step.\u201d\n\u2022 Constraints and Instructions : I look for specific rules to follow. For \nexample, your prompt asked for a step-by-step explanation. My internal \n A. Gull\u00ed",
        "329\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2025\nA. Gull\u00ed, Agentic Design Patterns, https://doi.org/10.1007/978-3-032-01402-3_22\n22\nAdvanced Prompting Techniques\n Introduction to\u00a0Prompting\nPrompting, the primary interface for interacting with language models, is the \nprocess of crafting inputs to guide the model towards generating a desired \noutput. This involves structuring requests, providing relevant context, speci -\nfying the output format, and demonstrating expected response types. Well-  \ndesigned prompts can maximize the potential of language models, resulting in \naccurate, relevant, and creative responses. In contrast, poorly designed \nprompts can lead to ambiguous, irrelevant, or erroneous outputs.\nThe objective of prompt engineering is to consistently elicit high-quality \nresponses from language models. This requires understanding the capabilities \nand limitations of the models and effectively communicating intended goals. \nIt involves developing expertise in communicating with AI by learning how to \nbest instruct it.\nThis chapter details various prompting techniques that extend beyond basic \ninteraction methods. It explores methodologies for structuring complex \nrequests, enhancing the model\u2019s reasoning abilities, controlling output for -\nmats, and integrating external information. These techniques are applicable to \nbuilding a range of applications, from simple chatbots to complex multi-agent \nsystems, and can improve the performance and reliability of agentic \napplications.\nAgentic patterns, the architectural structures for building intelligent sys -\ntems, are detailed in the main chapters. These patterns define how agents \nplan, utilize tools, manage memory, and collaborate. The efficacy of these",
        "350\n \u2013 Prompt 2: \u201cWrite the introduction section based on this outline: [insert \noutline intro].\u201d\n \u2013 Prompt 3: \u201cWrite the section on \u2018Impact on White-Collar Jobs\u2019 based on \nthis outline: [insert outline section].\u201d (Repeat for other sections).\n \u2013 Prompt N: \u201cCombine these sections and write a conclusion.\u201d\n Retrieval Augmented Generation (RAG)\nRAG is a powerful technique that enhances language models by giving them \naccess to external, up-to-date, or domain-specific information during the \nprompting process. When a user asks a question, the system first retrieves \nrelevant documents or data from a knowledge base (e.g., a database, a set of \ndocuments, the web). This retrieved information is then included in the \nprompt as context, allowing the language model to generate a response \ngrounded in that external knowledge. This mitigates issues like hallucination \nand provides access to information the model wasn\u2019t trained on or that is very \nrecent. This is a key pattern for agentic systems that need to work with \ndynamic or proprietary information.\n\u2022 Example:\n \u2013 User Query: \u201cWhat are the new features in the latest version of the \nPython library \u2018X\u2019?\u201d\n \u2013 System Action: Search a documentation database for \u201cPython library X \nlatest features\u201d.\n \u2013 Prompt to LLM : \u201cBased on the following documentation snippets: \n[insert retrieved text], explain the new features in the latest version of \nPython library \u2018X\u2019.\u201d\n Persona Pattern (User Persona)\nWhile role prompting assigns a persona to the model, the Persona Pattern \ninvolves describing the user or the target audience for the model\u2019s output. \nThis helps the model tailor its response in terms of language, complexity, \ntone, and the kind of information it provides.\n A. Gull\u00ed"
      ],
      "reference": "ReAct stands for Reason + Act. Instead of asking an LLM to solve a problem in one go, this pattern forces it to loop through three steps: 1. Thought: 'I need to find the user's username first.' 2. Action: Calls get_user_info(id=123). 3. Observation: Receives 'John Doe'. Repeat. It is more effective because it reduces hallucinations by grounding every step in real data (Observations) and allows the model to self-correct if an action fails."
    },
    {
      "user_input": "What is the 'Reflection' pattern, and when would you use it?",
      "response": "The Reflection pattern is an agentic design pattern that enables agents to iteratively improve their outputs by evaluating them for quality, accuracy, or adherence to predefined criteria. It involves a feedback loop where the agent (producer) generates an output, which is then evaluated (critiqued) and refined based on this evaluation. This process allows for self-correction and enhancement of performance over time.\n\n### Key Aspects:\n1. **Self-Correction Mechanism**: The agent evaluates its own output or internal state to identify areas for improvement.\n2. **Feedback Loop**: Outputs are evaluated by the agent itself (self-reflection) or a separate critic, providing structured feedback.\n3. **State Management**: Required for maintaining context during iterative processes, especially in complex workflows.\n4. **Integration with Other Patterns**: Can be combined with patterns like Planning, Collaboration, and Memory Management to create sophisticated systems.\n5. **Use Cases**:\n   - **Iterative Processes**: Such as drafting reports or refining Python functions, where multiple rounds of evaluation improve results.\n   - **Complex Tasks**: Enhancing the quality of outputs in areas requiring high precision, like content generation.\n\nThe Reflection pattern is particularly useful when output quality and adherence to complex constraints are paramount. It complements other patterns to build robust, adaptable systems capable of handling intricate tasks through iterative refinement.",
      "retrieved_contexts": [
        "47\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2025\nA. Gull\u00ed, Agentic Design Patterns, https://doi.org/10.1007/978-3-032-01402-3_4\n4\nReflection\n Reflection Pattern Overview\nIn the preceding chapters, we\u2019ve explored fundamental agentic patterns: \nChaining for sequential execution, Routing for dynamic path selection, and \nParallelization for concurrent task execution. These patterns enable agents to \nperform complex tasks more efficiently and flexibly. However, even with \nsophisticated workflows, an agent\u2019s initial output or plan might not be opti -\nmal, accurate, or complete. This is where the Reflection pattern comes \ninto play.\nThe Reflection pattern involves an agent evaluating its own work, output, \nor internal state and using that evaluation to improve its performance or refine \nits response. It\u2019s a form of self-correction or self-improvement, allowing the \nagent to iteratively refine its output or adjust its approach based on feedback, \ninternal critique, or comparison against desired criteria. Reflection can occa -\nsionally be facilitated by a separate agent whose specific role is to analyze the \noutput of an initial agent.\nUnlike a simple sequential chain where output is passed directly to the next \nstep, or routing which chooses a path, reflection introduces a feedback loop. \nThe agent doesn\u2019t just produce an output; it then examines that output (or \nthe process that generated it), identifies potential issues or areas for improve-\nment, and uses those insights to generate a better version or modify its future \nactions.",
        "57\nWhy The Reflection pattern offers a solution by introducing a mechanism \nfor self-correction and refinement. It establishes a feedback loop where a \u201cpro-\nducer\u201d agent generates an output, and then a \u201ccritic\u201d agent (or the producer \nitself) evaluates it against predefined criteria. This critique is then used to \ngenerate an improved version. This iterative process of generation, evaluation, \nand refinement progressively enhances the quality of the final result, leading \nto more accurate, coherent, and reliable outcomes.\nRule of Thumb Use the Reflection pattern when the quality, accuracy, and \ndetail of the final output are more important than speed and cost. It is par -\nticularly effective for tasks like generating polished long-  form content, writ-\ning and debugging code, and creating detailed plans. Employ a separate critic \nagent when tasks require high objectivity or specialized evaluation that a gen-\neralist producer agent might miss.\nVisual Summary (Figs. 4.1 and 4.2)\nFig. 4.1 Reflection design pattern, self-reflection\n4 Reflection",
        "59\n Conclusion\nThe reflection pattern provides a crucial mechanism for self-correction within \nan agent\u2019s workflow, enabling iterative improvement beyond a single-pass \nexecution. This is achieved by creating a loop where the system generates an \noutput, evaluates it against specific criteria, and then uses that evaluation to \nproduce a refined result. This evaluation can be performed by the agent itself \n(self-reflection) or, often more effectively, by a distinct critic agent, which \nrepresents a key architectural choice within the pattern.\nWhile a fully autonomous, multi-step reflection process requires a robust \narchitecture for state management, its core principle is effectively demon-\nstrated in a single generate-critique-refine cycle. As a control structure, reflec-\ntion can be integrated with other foundational patterns to construct more \nrobust and functionally complex agentic systems.\nBibliography\nGoogle Agent Developer Kit (ADK) Documentation (Multi-Agent Systems): https://\ngoogle.github.io/adk- docs/agents/multi- agents/\nLangChain Expression Language (LCEL) Documentation: https://python.langchain.\ncom/docs/introduction/\nLangGraph Documentation: https://www.langchain.com/langgraph\nT raining Language Models to Self-Correct via Reinforcement Learning: https://arxiv.\norg/abs/2409.12917\n4 Reflection",
        "58\nFig. 4.2 Reflection design pattern, producer and critique agent\n Key Takeaways\n\u2022 The primary advantage of the Reflection pattern is its ability to iteratively \nself-correct and refine outputs, leading to significantly higher quality, accu-\nracy, and adherence to complex instructions.\n\u2022 It involves a feedback loop of execution, evaluation/critique, and refine -\nment. Reflection is essential for tasks requiring high-quality, accurate, or \nnuanced outputs.\n\u2022 A powerful implementation is the Producer-Critic model, where a separate \nagent (or prompted role) evaluates the initial output. This separation of \nconcerns enhances objectivity and allows for more specialized, struc -\ntured feedback.\n\u2022 However, these benefits come at the cost of increased latency and compu-\ntational expense, along with a higher risk of exceeding the model\u2019s context \nwindow or being throttled by API services.\n\u2022 While full iterative reflection often requires stateful workflows (like \nLangGraph), a single reflection step can be implemented in LangChain \nusing LCEL to pass output for critique and subsequent refinement.\n\u2022 Google ADK can facilitate reflection through sequential workflows where \none agent\u2019s output is critiqued by another agent, allowing for subsequent \nrefinement steps.\n\u2022 This pattern enables agents to perform self-correction and enhance their \nperformance over time.\n A. Gull\u00ed",
        "49\nthe output. The provided LangChain and ADK code examples both imple -\nment this two-agent model: the LangChain example uses a specific \u201creflector \nprompt\u201d to create a critic persona, while the ADK example explicitly defines \na producer and a reviewer agent.\nImplementing reflection often requires structuring the agent\u2019s workflow to \ninclude these feedback loops. This can be achieved through iterative loops in \ncode, or using frameworks that support state management and conditional \ntransitions based on evaluation results. While a single step of evaluation and \nrefinement can be implemented within either a LangChain/LangGraph, or \nADK, or Crew.AI chain, true iterative reflection typically involves more com-\nplex orchestration.\nThe Reflection pattern is crucial for building agents that can produce high- \nquality outputs, handle nuanced tasks, and exhibit a degree of self-awareness \nand adaptability. It moves agents beyond simply executing instructions \ntowards a more sophisticated form of problem-solving and content generation.\nThe intersection of reflection with goal setting and monitoring (see Chap. \n11) is worth noticing. A goal provides the ultimate benchmark for the agent\u2019s \nself-evaluation, while monitoring tracks its progress. In a number of practical \ncases, Reflection then might act as the corrective engine, using monitored \nfeedback to analyze deviations and adjust its strategy. This synergy transforms \nthe agent from a passive executor into a purposeful system that adaptively \nworks to achieve its objectives.\nFurthermore, the effectiveness of the Reflection pattern is significantly \nenhanced when the LLM keeps a memory of the conversation (see Chap. 8). \nThis conversational history provides crucial context for the evaluation phase, \nallowing the agent to assess its output not just in isolation, but against the \nbackdrop of previous interactions, user feedback, and evolving goals. It enables \nthe agent to learn from past critiques and avoid repeating errors. Without \nmemory, each reflection is a self-contained event; with memory, reflection \nbecomes a cumulative process where each cycle builds upon the last, leading \nto more intelligent and context-aware refinement.\n Practical Applications and\u00a0Use Cases\nThe Reflection pattern is valuable in scenarios where output quality, accuracy, \nor adherence to complex constraints is critical:\n4 Reflection",
        "416\nagent, using the initial plan as its outline, would synthesize the collected \ninformation into a coherent draft.\n\u2022 Iterative Reflection and Refinement:  A first draft is rarely perfect. The \nReflection pattern could be implemented by introducing a third \u201cCritic\u201d \nagent. This agent\u2019s sole purpose would be to review the Writer\u2019s draft, \nchecking for logical inconsistencies, factual inaccuracies, or areas lacking \nclarity. Its critique would be fed back to the Writer agent, which would \nthen leverage the Self-Correction pattern to refine its output, incorporating \nthe feedback to produce a higher-quality final report.\n\u2022 State Management:  Throughout this entire process, a Memory \nManagement system would be essential. It would maintain the state of the \nresearch plan, store the information gathered by the Researcher, hold the \ndrafts created by the Writer, and track the feedback from the Critic, ensur-\ning that context is preserved across the entire multi-step, multi-\nagent workflow.\nIn this example, at least five distinct agentic patterns are woven together. The \nPlanning pattern provides the high-level structure, T ool Use grounds the \noperation in real-world data, Multi-Agent Collaboration enables specializa -\ntion and division of labor, Reflection ensures quality, and Memory \nManagement maintains coherence. This composition transforms a set of indi-\nvidual capabilities into a powerful, autonomous system capable of tackling a \ntask that would be far too complex for a single prompt or a simple chain.\n Looking to\u00a0the\u00a0Future\nThe composition of agentic patterns into complex systems, as illustrated by \nour AI research assistant, is not the end of the story but rather the beginning \nof a new chapter in software development. As we look ahead, several emerging \ntrends and challenges will define the next generation of intelligent systems, \npushing the boundaries of what is possible and demanding even greater \nsophistication from their creators.\nThe journey toward more advanced agentic AI will be marked by a drive for \ngreater autonomy and reasoning. The patterns we have discussed provide the \nscaffolding for goal-oriented behavior, but the future will require agents that \ncan navigate ambiguity, perform abstract and causal reasoning, and even \nexhibit a degree of common sense.",
        "51\n Planning and\u00a0Strategy\nEvaluating a proposed plan and identifying potential flaws or improvements.\n\u2022 Use Case: An agent planning a series of actions to achieve a goal.\n \u2013 Reflection: Generate a plan, simulate its execution or evaluate its feasi-\nbility against constraints, revise the plan based on the evaluation.\n \u2013 Benefit: Develops more effective and realistic plans.\n Conversational Agents\nReviewing previous turns in a conversation to maintain context, correct mis-\nunderstandings, or improve response quality.\n\u2022 Use Case: A customer support chatbot.\n \u2013 Reflection: After a user response, review the conversation history and \nthe last generated message to ensure coherence and address the user\u2019s \nlatest input accurately.\n \u2013 Benefit: Leads to more natural and effective conversations.\nReflection adds a layer of meta-cognition to agentic systems, enabling them to \nlearn from their own outputs and processes, leading to more intelligent, reli -\nable, and high-quality results.\n Hands-On Code Example (LangChain)\nThe implementation of a complete, iterative reflection process necessitates \nmechanisms for state management and cyclical execution. While these are \nhandled natively in graph-based frameworks like LangGraph or through cus-\ntom procedural code, the fundamental principle of a single reflection cycle \ncan be demonstrated effectively using the compositional syntax of LCEL \n(LangChain Expression Language).\nThis example implements a reflection loop using the Langchain library and \nOpenAI\u2019s GPT-4o model to iteratively generate and refine a Python function \nthat calculates the factorial of a number. The process starts with a task prompt, \ngenerates initial code, and then repeatedly reflects on the code based on cri -\ntiques from a simulated senior software engineer role, refining the code in \neach iteration until the critique stage determines the code is perfect or a \n4 Reflection"
      ],
      "reference": "Reflection is a pattern where an agent critiques its own output.Workflow: Agent generates a draft $\rightarrow$ Agent prompts itself: 'Are there errors in this code?' $\rightarrow$ Agent generates critique $\rightarrow$ Agent rewrites draft based on critique.Use Case: High-stakes tasks like coding (debugging itself) or creative writing, where an iterative 'draft-revise' loop produces significantly higher quality than a zero-shot attempt."
    },
    {
      "user_input": "In a Multi-Agent 'Orchestrator-Workers' pattern, what is the role of the Orchestrator, and what is a common risk?",
      "response": "In the Multi-Agent 'Orchestrator-Workers' pattern, the role of the Orchestrator is to act as the central leader, managing tasks, ensuring proper context setup, and validating agent work. A common risk associated with this approach is the potential for coordination issues or miscommunication between agents if not properly designed.\n\n**Answer:**\nThe Orchestrator's role is to serve as the central leader of multiple specialized agents, defining tasks, setting up the necessary context, and ensuring that each agent's contributions are aligned toward achieving the overall goal. A common risk in this pattern is the potential for coordination issues or miscommunication between agents if not properly managed.",
      "retrieved_contexts": [
        "407\nClaude Opus 4, OpenAI, DeepSeek, etc). Using less powerful models or \nrouting requests through intermediary platforms that obscure or truncate \ncontext will degrade performance. The framework is built on creating the \npurest possible dialogue between the human lead and the raw capabilities \nof the underlying model, ensuring each agent operates at its peak potential.\nThe framework is structured as a team of specialized agents, each designed for \na core function in the development lifecycle. The human developer acts as the \ncentral orchestrator, delegating tasks and integrating the results.\n Core Components\nT o effectively leverage a frontier Large Language Model, this framework \nassigns distinct development roles to a team of specialized agents. These agents \nare not separate applications but are conceptual personas invoked within the \nLLM through carefully crafted, role-specific prompts and contexts. This \napproach ensures that the model\u2019s vast capabilities are precisely focused on the \ntask at hand, from writing initial code to performing a nuanced, critical review.\nThe Orchestrator: The Human Developer\n In this collaborative framework, \nthe human developer acts as the Orchestrator, serving as the central intelli -\ngence and ultimate authority over the AI agents. Role: T eam Lead, Architect, \nand final decision-maker. The orchestrator defines tasks, prepares the context, \nand validates all work done by the agents.\n\u2022 Interface: The developer\u2019s own terminal, editor, and the native web \nUI of the chosen Agents.\nThe Context Staging Area As the foundation for any successful agent inter-\naction, the Context Staging Area is where the human developer meticulously \nprepares a complete and task-specific briefing.  Role: A dedicated workspace \nfor each task, ensuring agents receive a complete and accurate briefing.\n\u2022 Implementation: A temporary directory (task-context/) containing \nmarkdown files for goals, code files, and relevant docs\nThe Specialist Agents  By using targeted prompts, we can build a team of \nspecialist agents, each tailored for a specific development task.\n28 Coding Agents",
        "113\n Key Takeaways\n\u2022 Multi-Agent collaboration involves multiple agents working together to \nachieve a common goal.\n\u2022 This pattern leverages specialized roles, distributed tasks, and inter-agent \ncommunication.\n\u2022 Collaboration can take forms like sequential handoffs, parallel processing, \ndebate, or hierarchical structures.\n\u2022 This pattern is ideal for complex problems requiring diverse expertise or \nmultiple distinct stages.\n Conclusion\nThis chapter explored the Multi-Agent Collaboration pattern, demonstrating \nthe benefits of orchestrating multiple specialized agents within systems. We \nexamined various collaboration models, emphasizing the pattern\u2019s essential \nrole in addressing complex, multifaceted problems across diverse domains. \nUnderstanding agent collaboration naturally leads to an inquiry into their \ninteractions with the external environment.\nBibliography\nMulti-Agent Collaboration Mechanisms: A Survey of LLMs: https://arxiv.org/\nabs/2501.06322\nMulti-Agent System \u2014 The Power of Collaboration: https://aravindakumar.medium.\ncom/introducing-  multi-  agent-  frameworks-  the-  power-  of-  collaboration-   \ne9db31bba1b6\n7 Multi-Agent Collaboration",
        "112\nWhy The Multi-Agent Collaboration pattern offers a standardized solution \nby creating a system of multiple, cooperating agents. A complex problem is \nbroken down into smaller, more manageable sub-problems. Each sub-prob -\nlem is then assigned to a specialized agent with the precise tools and capabili-\nties required to solve it. These agents work together through defined \ncommunication protocols and interaction models like sequential handoffs, \nparallel workstreams, or hierarchical delegation. This agentic, distributed \napproach creates a synergistic effect, allowing the group to achieve outcomes \nthat would be impossible for any single agent.\nRule of Thumb  Use this pattern when a task is too complex for a single \nagent and can be decomposed into distinct sub-tasks requiring specialized \nskills or tools. It is ideal for problems that benefit from diverse expertise, par-\nallel processing, or a structured workflow with multiple stages, such as com -\nplex research and analysis, software development, or creative content \ngeneration.\nVisual Summary (Fig. 7.3)\nFig. 7.3 Multi-Agent design pattern\n A. Gull\u00ed",
        "98\n Multi-Agent Collaboration Pattern Overview\nThe Multi-Agent Collaboration pattern involves designing systems where \nmultiple independent or semi-independent agents work together to achieve a \ncommon goal. Each agent typically has a defined role, specific goals aligned \nwith the overall objective, and potentially access to different tools or knowl -\nedge bases. The power of this pattern lies in the interaction and synergy \nbetween these agents.\nCollaboration can take various forms:\n\u2022 Sequential Handoffs: One agent completes a task and passes its output to \nanother agent for the next step in a pipeline (similar to the Planning pat -\ntern, but explicitly involving different agents).\n\u2022 Parallel Processing: Multiple agents work on different parts of a problem \nsimultaneously, and their results are later combined.\n\u2022 Debate and Consensus:  Multi-Agent Collaboration where Agents with \nvaried perspectives and information sources engage in discussions to evalu-\nate options, ultimately reaching a consensus or a more informed decision.\n\u2022 Hierarchical Structures: A manager agent might delegate tasks to worker \nagents dynamically based on their tool access or plugin capabilities and \nsynthesize their results. Each agent can also handle relevant groups of tools, \nrather than a single agent handling all the tools.\n\u2022 Expert T eams: Agents with specialized knowledge in different domains \n(e.g., a researcher, a writer, an editor) collaborate to produce a com -\nplex output.\n\u2022 Critic-Reviewer: Agents create initial outputs such as plans, drafts, or \nanswers. A second group of agents then critically assesses this output for \nadherence to policies, security, compliance, correctness, quality, and align-\nment with organizational objectives. The original creator or a final agent \nrevises the output based on this feedback. This pattern is particularly effec-\ntive for code generation, research writing, logic checking, and ensuring \nethical alignment. The advantages of this approach include increased \nrobustness, improved quality, and a reduced likelihood of hallucinations \nor errors.\nA multi-agent system (see Fig. 7.1) fundamentally comprises the delineation \nof agent roles and responsibilities, the establishment of communication chan-\nnels through which agents exchange information, and the formulation of a \ntask flow or interaction protocol that directs their collaborative endeavors.\n A. Gull\u00ed",
        "97\u00a9 The Author(s), under exclusive license to Springer Nature Switzerland AG 2025\nA. Gull\u00ed, Agentic Design Patterns, https://doi.org/10.1007/978-3-032-01402-3_7\n7\nMulti-Agent Collaboration\nWhile a monolithic agent architecture can be effective for well-defined \nproblems, its capabilities are often constrained when faced with complex, \nmulti- domain tasks. The Multi-Agent Collaboration pattern addresses \nthese limitations by structuring a system as a cooperative ensemble of dis -\ntinct, specialized agents. This approach is predicated on the principle of \ntask decomposition, where a high-level objective is broken down into dis -\ncrete sub-problems. Each sub-problem is then assigned to an agent possess -\ning the specific tools, data access, or reasoning capabilities best suited for \nthat task.\nFor example, a complex research query might be decomposed and assigned \nto a Research Agent for information retrieval, a Data Analysis Agent for sta -\ntistical processing, and a Synthesis Agent for generating the final report. The \nefficacy of such a system is not merely due to the division of labor but is criti-\ncally dependent on the mechanisms for inter-agent communication. This \nrequires a standardized communication protocol and a shared ontology, \nallowing agents to exchange data, delegate sub-tasks, and coordinate their \nactions to ensure the final output is coherent.\nThis distributed architecture offers several advantages, including enhanced \nmodularity, scalability, and robustness, as the failure of a single agent does \nnot necessarily cause a total system failure. The collaboration allows for a \nsynergistic outcome where the collective performance of the multi-agent sys-\ntem surpasses the potential capabilities of any single agent within the \nensemble.",
        "172\nA more robust approach involves separating these concerns by giving spe-\ncific roles to a crew of agents. For instance, I have built a personal crew of AI \nagents using Gemini where each has a specific role:\n\u2022 The Peer Programmer: Helps write and brainstorm code.\n\u2022 The Code Reviewer: Catches errors and suggests improvements.\n\u2022 The Documenter: Generates clear and concise documentation.\n\u2022 The T est Writer: Creates comprehensive unit tests.\n\u2022 The Prompt Refiner: Optimizes interactions with the AI.\nIn this multi-agent system, the Code Reviewer, acting as a separate entity \nfrom the programmer agent, has a prompt similar to the judge in the example, \nwhich significantly improves objective evaluation. This structure naturally \nleads to better practices, as the T est Writer agent can fulfill the need to write \nunit tests for the code produced by the Peer Programmer.\nI leave to the interested reader the task of adding these more sophisticated \ncontrols and making the code closer to production-ready.\n At a\u00a0Glance\nWhat AI agents often lack a clear direction, preventing them from acting \nwith purpose beyond simple, reactive tasks. Without defined objectives, they \ncannot independently tackle complex, multi-step problems or orchestrate \nsophisticated workflows. Furthermore, there is no inherent mechanism for \nthem to determine if their actions are leading to a successful outcome. This \nlimits their autonomy and prevents them from being truly effective in \ndynamic, real-world scenarios where mere task execution is insufficient.\nWhy\n The Goal Setting and Monitoring pattern provides a standardized solu-\ntion by embedding a sense of purpose and self-  assessment into agentic sys -\ntems. It involves explicitly defining clear, measurable objectives for the agent \nto achieve. Concurrently, it establishes a monitoring mechanism that contin-\nuously tracks the agent\u2019s progress and the state of its environment against \nthese goals. This creates a crucial feedback loop, enabling the agent to assess \nits performance, correct its course, and adapt its plan if it deviates from the \npath to success. By implementing this pattern, developers can transform sim-\n A. Gull\u00ed",
        "This manager \nwould orchestrate the entire process by delegating tasks to other specialized \nagents: a \u201cMarket Research\u201d agent to gather consumer data, a \u201cProduct \nDesign\u201d agent to develop concepts, and a \u201cMarketing\u201d agent to craft promo-\ntional materials. The key to their success would be seamless communication \nand information sharing between them, ensuring that all individual efforts \nalign to achieve the collective goal."
      ],
      "reference": "Role: The Orchestrator is a 'Router' LLM. It breaks a complex user query into sub-tasks and delegates them to specialized 'Worker' agents (e.g., a 'Coder' agent and a 'Researcher' agent). It then synthesizes their results. Risk: The Bottleneck Risk. If the Orchestrator fails to decompose the task correctly or passes context poorly between workers, the entire system fails. Also, it adds latency and cost because every request passes through a 'Manager' model before work begins."
    },
    {
      "user_input": "You are building an Agentic RAG that keeps getting stuck in an infinite loop (searching the same thing forever). How do you architecturally prevent this?",
      "response": "To prevent an Agentic RAG system from getting stuck in an infinite loop, several strategies can be implemented:\n\n1. **Implement a Session State Check**: Introduce a ConditionChecker agent that monitors the session state and terminates the loop once the process is complete. This ensures that the loop knows when it has achieved its objective or reached a predefined condition.\n\n2. **Set Iteration Limits**: Utilize the max_iterations parameter in the LoopAgent to define a maximum number of steps or iterations. This prevents the system from running indefinitely beyond a specified threshold.\n\n3. **Error Handling and Termination**: Incorporate mechanisms to detect errors during iteration. If an iteration fails, the system should be designed to stop and handle the error appropriately, preventing indefinite looping due to unexpected issues.\n\nBy integrating these components\u2014ConditionChecker for termination based on session state, max_iterations for defined loop limits, and robust error handling\u2014the Agentic RAG can efficiently manage its processes without getting stuck in infinite loops.",
      "retrieved_contexts": [
        "208\n Conclusion\nIn conclusion, Retrieval-Augmented Generation (RAG) addresses the core \nlimitation of a Large Language Model\u2019s static knowledge by connecting it to \nexternal, up-to-date data sources. The process works by first retrieving rele -\nvant information snippets and then augmenting the user\u2019s prompt, enabling \nthe LLM to generate more accurate and contextually aware responses. This is \nmade possible by foundational technologies like embeddings, semantic search, \nand vector databases, which find information based on meaning rather than \njust keywords. By grounding outputs in verifiable data, RAG significantly \nreduces factual errors and allows for the use of proprietary information, \nenhancing trust through citations.\nAn advanced evolution, Agentic RAG, introduces a reasoning layer that \nactively validates, reconciles, and synthesizes retrieved knowledge for even \ngreater reliability. Similarly, specialized approaches like GraphRAG leverage \nknowledge graphs to navigate explicit data relationships, allowing the system \nto synthesize answers to highly complex, interconnected queries. This agent \ncan resolve conflicting information, perform multi-step queries, and use exter-\nnal tools to find missing data. While these advanced methods add complexity \nand latency, they drastically improve the depth and trustworthiness of the \nfinal response. Practical applications for these patterns are already transform-\ning industries, from enterprise search and customer support to personalized \ncontent delivery. Despite the challenges, RAG is a crucial pattern for making \nAI more knowledgeable, reliable, and useful. Ultimately, it transforms LLMs \nfrom closed-book conversationalists into powerful, open-book reasoning tools.\nBibliography\nGoogle AI for Developers Documentation.",
        "107\nimport asyncio\nfrom typing import AsyncGenerator\nfrom google.adk.agents import LoopAgent, LlmAgent, BaseAgent\nfrom google.adk.events import Event, EventActions\nfrom google.adk.agents.invocation_context import  \nInvocationContext\n# Best Practice: Define custom agents as complete, self-describ-\ning classes.\nclass ConditionChecker(BaseAgent):\n   \"\"\"A custom agent that checks for a 'completed' status in the \nsession state.\"\"\"\n   name: str = \"ConditionChecker\"\n   description: str = \"Checks if a process is complete and sig-\nnals the loop to stop.\"\n   async def _run_async_impl(\n       self, context: InvocationContext\n   ) -> AsyncGenerator[Event, None]:\n       \"\"\"Checks state and yields an event to either continue or \nstop the loop.\"\"\"\n       status = context.session.state.get(\"status\", \"pending\")\n       is_done = (status == \"completed\")\n       if is_done:\n           # Escalate to terminate the loop when the condi -\ntion is met.\n           yield Event(author=self.name, actions=EventActions(es\ncalate=True))\n       else:\n           # Yield a simple event to continue the loop.\n           yield Event(author=self.name, content=\"Condition not \nmet, continuing loop.\")\n# Correction: The LlmAgent must have a model and clear instructions.\nprocess_step = LlmAgent(\n   name=\"ProcessingStep\",\n   model=\"gemini-2.0-flash-exp\",\n   instruction=\"You are a step in a longer process. Perform your \ntask. If you are the final step, update session state by setting \n'status' to 'completed'.\"\n)\n# The LoopAgent orchestrates the workflow.\npoller = LoopAgent(\n   name=\"StatusPoller\",\n   max_iterations=10,\n   sub_agents=[\n       process_step,\n       ConditionChecker() # Instantiating the well-defined cus-\ntom agent.\n   ]\n)\n# This poller will now execute 'process_step'\n# and then 'ConditionChecker'\n# repeatedly until the status is 'completed' or 10 iterations\n# have passed.\n7 Multi-Agent Collaboration",
        "198\ngeneration process, RAG addresses some of the core limitations of standalone \nLLMs. The foundational concepts of embeddings and semantic similarity, \ncombined with retrieval techniques like keyword and hybrid search, allow the \nsystem to intelligently find relevant information, which is made manageable \nthrough strategic chunking. This entire retrieval process is powered by special-\nized vector databases designed to store and efficiently query millions of \nembeddings at scale. While challenges in retrieving fragmented or contradic-\ntory information persist, RAG empowers LLMs to produce answers that are \nnot only contextually appropriate but also anchored in verifiable facts, foster-\ning greater trust and utility in AI.\n Graph RAG\nGraphRAG is an advanced form of Retrieval-Augmented Generation that uti-\nlizes a knowledge graph instead of a simple vector database for information \nretrieval. It answers complex queries by navigating the explicit relationships \n(edges) between data entities (nodes) within this structured knowledge base. \nA key advantage is its ability to synthesize answers from information frag-\nmented across multiple documents, a common failing of traditional RAG. By \nunderstanding these connections, GraphRAG provides more contextually \naccurate and nuanced responses.\nUse cases include complex financial analysis, connecting companies to \nmarket events, and scientific research for discovering relationships between \ngenes and diseases. The primary drawback, however, is the significant com -\nplexity, cost, and expertise required to build and maintain a high-quality \nknowledge graph. This setup is also less flexible and can introduce higher \nlatency compared to simpler vector search systems. The system\u2019s effectiveness \nis entirely dependent on the quality and completeness of the underlying graph \nstructure. Consequently, GraphRAG offers superior contextual reasoning for \nintricate questions but at a much higher implementation and maintenance \ncost. In summary, it excels where deep, interconnected insights are more criti-\ncal than the speed and simplicity of standard RAG.\n Agentic RAG\nAn evolution of this pattern, known as Agentic RAG (see Fig.  14.2), intro-\nduces a reasoning and decision-making layer to significantly enhance the reli-\nability of information extraction. Instead of just retrieving and augmenting, \n A. Gull\u00ed",
        "171\nIf the verdict is \u201cFalse,\u201d the AI doesn\u2019t give up. It enters a thoughtful revi-\nsion phase, using the insights from its self-critique to pinpoint the weaknesses \nand intelligently rewrite the code. This cycle of drafting, self-reviewing, and \nrefining continues, with each iteration aiming to get closer to the goals. This \nprocess repeats until the AI finally achieves a \u201cT rue\u201d status by satisfying every \nrequirement, or until it reaches a predefined limit of attempts, much like a \ndeveloper working against a deadline. Once the code passes this final inspec -\ntion, the script packages the polished solution, adding helpful comments and \nsaving it to a clean, new Python file, ready for use.\n Caveats and\u00a0Considerations\nIt is important to note that this is an exemplary illustration and not production- \nready code. For real-world applications, several factors must be taken into \naccount. An LLM may not fully grasp the intended meaning of a goal and \nmight incorrectly assess its performance as successful. Even if the goal is well \nunderstood, the model may hallucinate. When the same LLM is responsible \nfor both writing the code and judging its quality, it may have a harder time \ndiscovering it is going in the wrong direction.\nUltimately, LLMs do not produce flawless code by magic; you still need to \nrun and test the produced code. Furthermore, the \u201cmonitoring\u201d in the simple \nexample is basic and creates a potential risk of the process running forever.\nAct as an expert code reviewer with a deep commitment to produc-\ning clean, correct, and simple code. Your core mission is to \neliminate code \"hallucinations\" by ensuring every suggestion is \ngrounded in reality and best practices.\nWhen I provide you with a code snippet, I want you to:\n-- Identify and Correct Errors: Point out any logical flaws, \nbugs, or potential runtime errors.\n-- Simplify and Refactor: Suggest changes that make the code \nmore readable, efficient, and maintainable without sacrificing \ncorrectness.\n-- Provide Clear Explanations: For every suggested change, \nexplain why it is an improvement, referencing principles of \nclean code, performance, or security.",
        "xv Prologue \nFig. 2 Transitioning from LLMs to RAG, then to agentic RAG, and finally to agentic AI\nFig. 3 Various instances demonstrating the spectrum of agent complexity",
        "Stopping \niteration.\")\n           break\n       print(\"\n  Goals not fully met. Preparing for next \niteration...\")\n11 Goal Setting and Monitoring",
        "37\n#    along with the original topic, will be fed into the \nnext step.\nmap_chain = RunnableParallel(\n   {\n       \"summary\": summarize_chain,\n       \"questions\": questions_chain,\n       \"key_terms\": terms_chain,\n       \"topic\": RunnablePassthrough(),  # Pass the original \ntopic through\n   }\n)\n# 2. Define the final synthesis prompt which will combine the \nparallel results.\nsynthesis_prompt = ChatPromptTemplate.from_messages([\n   (\"system\", \"\"\"Based on the following information:\n    Summary: {summary}\n    Related Questions: {questions}\n    Key Terms: {key_terms}\n    Synthesize a comprehensive answer.\"\"\"),\n   (\"user\", \"Original topic: {topic}\")\n])\n# 3. Construct the full chain by piping the parallel results  \ndirectly\n#    into the synthesis prompt, followed by the LLM and output  \nparser.\nfull_parallel_chain = map_chain | synthesis_prompt | llm |  \nStrOutputParser()\n# --- Run the Chain ---\nasync def run_parallel_example(topic: str) -> None:\n   \"\"\"\n   Asynchronously invokes the parallel processing chain with  \na specific topic\n   and prints the synthesized result.\n   Args:\n       topic: The input topic to be processed by the LangChain  \nchains.\n   \"\"\"\n   if not llm:\n       print(\"LLM not initialized. Cannot run example.\")\n       return\n   print(f\"\\n--- Running Parallel LangChain Example for Topic:  \n'{topic}' ---\")\n   try:\n       # The input to 'ainvoke' is the single 'topic' string,\n       # then passed to each runnable in the 'map_chain'.\n       response = await full_parallel_chain.ainvoke(topic)\n       print(\"\\n--- Final Response ---\")\n       print(response)\n   except Exception as e:\n3 Parallelization"
      ],
      "reference": "You need to implement System-Level Guardrails (not just prompt engineering): Max Iterations: Hard limit the loop (e.g., max 10 steps). Cyclic Detection: Keep a history of 'Tools Used + Arguments.' If the agent calls search(query='finance') twice in a row, the system should intercept and force a stop or a query change. Time-to-Live (TTL): A 'Global Timeout' for the entire request to ensure the agent doesn't consume infinite compute."
    }
  ]
]